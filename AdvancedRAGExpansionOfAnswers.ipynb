{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269d87cb",
   "metadata": {},
   "source": [
    "### Pitfalls of RAG.\n",
    "* Limited Contextual understanding\n",
    "* They retrieve doucments solely based on keyword matching.\n",
    "* Qulaity and relevance of the retrived docs is firly poor. RAG does not rank the docs.\n",
    "* Poor Integration between retrieval and generation.\n",
    "* The LLMs can ignore the docs provided by RAG.\n",
    "* Naive RAGS suffer in large dataset. That is because of slower retrieval and inadequate indexing of the large dataset.\n",
    "* They lack robustness. They lack the ability to handle complex queries or ambiguous queries robustly.\n",
    "* They are inadaptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93780217",
   "metadata": {},
   "source": [
    "### Advanced RAG\n",
    "* Enhanced RAG RETRIEVAL.\n",
    "* Pre-Retrieval:\n",
    "    * Improving the indexing structure. and user's query.\n",
    "    * Improving data details, adding extra information\n",
    "* post- Retrievl:\n",
    "    * Combine pre-retrieval data with the original query.\n",
    "        * Re ranking to highlight important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb26b8",
   "metadata": {},
   "source": [
    "### Some Advanced RAG TECHNIQUES\n",
    "* Query Expansion:\n",
    "    * Generate potential answers to the query [using an LLM] and to get relevant context.\n",
    "        * In this: You first pass the original query to the LLM.. let it generate an answer_1.\n",
    "        * Next concatenate the query and the answer_1, into the vector database and again generate the Query_Result. \n",
    "        * Pass that into an LLM. Generate and answer.\n",
    "    * Use Cases (with generated answers):\n",
    "        * Information Retrieval\n",
    "        * Question Answering Systems\n",
    "        * E Commerce Search\n",
    "        * Academic Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e41e07",
   "metadata": {},
   "source": [
    "| Stage | Component | Description | Tools/Options |\n",
    "|-------|-----------|-------------|---------------|\n",
    "| **A** | **PDF Files** | Input documents | Raw PDF documents |\n",
    "| **B** | **Advanced Parser** | Extract and parse content from PDFs | LlamaParse, PyMuPDF |\n",
    "| **C** | **Chunking & Metadata** | Split content into manageable chunks with metadata | LlamaIndex, LangChain |\n",
    "| **D** | **Embeddings** | Convert text chunks into vector representations | OpenAI, HuggingFace, InstructorXL |\n",
    "| **E** | **Vector Database** | Store and index embeddings for similarity search | Chroma, Pinecone, FAISS |\n",
    "| **F** | **LLM Response** | Generate answers using retrieved context | Any LLM with retrieved context |\n",
    "\n",
    "## Pipeline Flow\n",
    "```\n",
    "PDF Files → Advanced Parser → Chunking & Metadata → Embeddings → Vector DB → LLM Response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c544c9",
   "metadata": {},
   "source": [
    "| Scenario                                       | Recommended Stack                          |\n",
    "| ---------------------------------------------- | ------------------------------------------ |\n",
    "| You want **high accuracy parsing with layout** | `PyMuPDF` or `Unstructured.io`             |\n",
    "| You want **fully managed RAG pipeline**        | `LlamaParse + LlamaIndex`                  |\n",
    "| You have **academic/research papers**          | `Grobid + LangChain`                       |\n",
    "| You want **minimal code, fast RAG MVP**        | `Embedchain` or `RAGatouille`              |\n",
    "| You have **scanned documents**                 | `PyMuPDF` + `Tesseract OCR` + `LayoutLMv3` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddac7c",
   "metadata": {},
   "source": [
    "| Library                                                                                              | Strengths                                   | Best For                                               |\n",
    "| ---------------------------------------------------------------------------------------------------- | ------------------------------------------- | ------------------------------------------------------ |\n",
    "| **[PyMuPDF (`fitz`)](https://pymupdf.readthedocs.io/)**                                              | Fast, supports images, fonts, layout info   | Structured parsing, extracting text **with layout**    |\n",
    "| **[pdfminer.six](https://github.com/pdfminer/pdfminer.six)**                                         | Fine-grained layout, text positioning       | Table & figure-aware parsing, **OCR fallback**         |\n",
    "| **[Grobid](https://github.com/kermitt2/grobid)**                                                     | ML-powered, structured data extraction      | Research papers, metadata extraction (titles, authors) |\n",
    "| **[LlamaParse (by LlamaIndex)](https://docs.llamaindex.ai/en/stable/examples/parser/llamaparse/)**   | Hosted API, uses layout + ML                | RAG pipelines (best for LLMs), **zero setup**          |\n",
    "| **[Unstructured.io](https://github.com/Unstructured-IO/unstructured)**                               | Parses HTML, PDFs, images, etc. into chunks | **General unstructured doc to structured JSON**        |\n",
    "| **[OCR + LayoutLMv3 (Hugging Face)](https://huggingface.co/docs/transformers/model_doc/layoutlmv3)** | Use for scanned PDFs or visual layouts      | Forms, invoices, scanned docs                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8eab2",
   "metadata": {},
   "source": [
    "# Advanced Agentic RAG Pipeline\n",
    "\n",
    "## Core RAG Components\n",
    "| Stage | Component | Description | Tools/Options |\n",
    "|-------|-----------|-------------|---------------|\n",
    "| **A** | **Document Ingestion** | Multi-format document input | PDF, DOCX, HTML, Web scraping |\n",
    "| **B** | **Intelligent Parser** | Context-aware parsing with metadata extraction | LlamaParse, Unstructured.io, PyMuPDF |\n",
    "| **C** | **Adaptive Chunking** | Dynamic chunking based on document structure | LlamaIndex, LangChain, Semantic chunking |\n",
    "| **D** | **Multi-Modal Embeddings** | Text + image embeddings with metadata | OpenAI, Cohere, BGE, InstructorXL |\n",
    "| **E** | **Hybrid Vector Store** | Vector + keyword + graph storage | Pinecone, Weaviate, Qdrant, Neo4j |\n",
    "\n",
    "## Agentic AI Layer\n",
    "| Stage | Agent Component | Description | Implementation |\n",
    "|-------|-----------------|-------------|----------------|\n",
    "| **F** | **Query Router** | Intelligently routes queries to appropriate retrievers | LangGraph, CrewAI, AutoGen |\n",
    "| **G** | **Multi-Agent Retriever** | Specialized agents for different retrieval strategies | Dense, sparse, hybrid, reranking agents |\n",
    "| **H** | **Context Synthesizer** | Combines and validates retrieved information | Cross-referencing and fact-checking agents |\n",
    "| **I** | **Response Orchestrator** | Plans and executes multi-step reasoning | Tool-calling agents with memory |\n",
    "| **J** | **Quality Assurance** | Validates and improves responses | Self-reflection and critique agents |\n",
    "\n",
    "## Advanced Features\n",
    "| Feature | Component | Description | Tools |\n",
    "|---------|-----------|-------------|-------|\n",
    "| **Memory** | **Conversation Memory** | Maintains context across interactions | LangGraph StateGraph, Redis |\n",
    "| **Planning** | **Task Decomposer** | Breaks complex queries into subtasks | ReAct, Plan-and-Execute patterns |\n",
    "| **Tools** | **Function Calling** | Accesses external APIs and databases | OpenAI Functions, LangChain Tools |\n",
    "| **Feedback** | **Learning Loop** | Improves based on user feedback | RLHF, preference learning |\n",
    "\n",
    "## Pipeline Flow\n",
    "```\n",
    "Documents → Intelligent Parser → Adaptive Chunking → Multi-Modal Embeddings → Hybrid Vector Store\n",
    "                                                                                      ↓\n",
    "User Query → Query Router → Multi-Agent Retriever → Context Synthesizer → Response Orchestrator → Quality Assurance → Final Response\n",
    "                ↑                                                                                           ↓\n",
    "            Memory & Planning ←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←← Feedback Loop\n",
    "```\n",
    "\n",
    "## Key Agentic Frameworks\n",
    "- **LangGraph**: State-based agent orchestration\n",
    "- **CrewAI**: Multi-agent collaboration framework  \n",
    "- **AutoGen**: Conversational multi-agent system\n",
    "- **LlamaIndex Agents**: Document-focused agent tools\n",
    "- **Haystack Agents**: Production-ready agent pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225187c",
   "metadata": {},
   "source": [
    "## Lets GO Hands-On"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b44af1",
   "metadata": {},
   "source": [
    "*heads up: we will be working on the microsoft annual report [85 pages]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbb5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\think\\anaconda3\\lib\\site-packages (1.0.10)\n",
      "Requirement already satisfied: pypdf in c:\\users\\think\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: ollama in c:\\users\\think\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (2.11.5)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\think\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (3.8.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (4.13.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (1.67.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from fastapi==0.115.9->chromadb) (0.41.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\think\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\think\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\think\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\think\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\think\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\think\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\think\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\think\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\think\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\think\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\think\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\think\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\think\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\think\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\think\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\think\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\think\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\think\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\think\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install chromadb pypdf ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468b82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting helper-utils\n",
      "  Downloading helper_utils-0.0.8.tar.gz (5.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\think\\anaconda3\\lib\\site-packages (from helper-utils) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\think\\anaconda3\\lib\\site-packages (from helper-utils) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pandas->helper-utils) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pandas->helper-utils) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pandas->helper-utils) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\think\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->helper-utils) (1.16.0)\n",
      "Building wheels for collected packages: helper-utils\n",
      "  Building wheel for helper-utils (setup.py): started\n",
      "  Building wheel for helper-utils (setup.py): finished with status 'done'\n",
      "  Created wheel for helper-utils: filename=helper_utils-0.0.8-py3-none-any.whl size=6087 sha256=a88f0e1aa7ea2189ab7f6c9a5270c5f8b6a334434e7786f8c3ab390e10e0886a\n",
      "  Stored in directory: c:\\users\\think\\appdata\\local\\pip\\cache\\wheels\\0d\\c9\\0b\\294fee31b3dc5173031699ea99432767ec851eef54c1982dd0\n",
      "Successfully built helper-utils\n",
      "Installing collected packages: helper-utils\n",
      "Successfully installed helper-utils-0.0.8\n"
     ]
    }
   ],
   "source": [
    "! pip install helper-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02bb56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0491e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the Text from pdfs \n",
    "# using pyPdf library\n",
    "def extract_text_from_pdfs(pdf_folder):\n",
    "    pdf_texts= []\n",
    "    for filename in os.listdir(pdf_folder):\n",
    "        pdf_path= os.path.join(pdf_folder, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            reader= PdfReader(pdf_path)\n",
    "            text=''\n",
    "            for page in reader.pages:\n",
    "                text+=page.extract_text().strip()\n",
    "            pdf_texts.append(text.strip()) # remove training whitespaces\n",
    "    return pdf_texts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "021f7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text= extract_text_from_pdfs('pdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd8423",
   "metadata": {},
   "source": [
    "Recursive Text Splitter: \n",
    "* The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. It seperates on this list.\n",
    "* How the text is split: `by list of characters.`\n",
    "* How the chunk size is measured: `by number of characters.`\n",
    "* To use this you first create a langchain document of your pdf/docx.\n",
    "* You can also change or update your seperator list.\n",
    "```\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    "    # Existing args\n",
    ")\n",
    "```\n",
    "* For more reference visit: https://python.langchain.com/docs/how_to/recursive_text_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text= '\\n'.join(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a944189",
   "metadata": {},
   "source": [
    "| Feature / Question                                 | `RecursiveCharacterTextSplitter`                                  | `SentenceTransformersTokenTextSplitter`                       |\n",
    "| -------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------- |\n",
    "| **Splits by**                                      | Number of **characters**                                          | Number of **tokens**                                          |\n",
    "| **Tokenizer-aware?**                               | ❌ No                                                              | ✅ Yes (uses `sentence-transformers` tokenizers)               |\n",
    "| **Preserves sentence structure?**                  | ❌ May break sentences                                             | ✅ Tries to preserve full sentences                            |\n",
    "| **Best use case**                                  | Fast, simple chunking; pre-token split                            | High-quality RAG, embedding models (like MiniLM, BGE, OpenAI) |\n",
    "| **When to use alone**                              | On small texts, for quick prototyping                             | When texts are small or already cleaned                       |\n",
    "| **When to combine both**                           | For huge/unstructured docs → rough cut (char) → fine cut (tokens) | After initial char-splitting for large inputs                 |\n",
    "| **Required to use both?**                          | ❌ No, optional                                                    | ❌ No, optional                                                |\n",
    "| **Does it handle token limits (e.g., 512, 1000)?** | ❌ No                                                              | ✅ Yes                                                         |\n",
    "| **Performance on large files**                     | ⚠️ Slower on huge files if not split beforehand                   | ✅ More efficient when pre-split                               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78409a7c",
   "metadata": {},
   "source": [
    "| Situation                        | What to Use                                    |\n",
    "| -------------------------------- | ---------------------------------------------- |\n",
    "| Small/medium PDFs or clean text  | ✅ Only `SentenceTransformersTokenTextSplitter` |\n",
    "| Large, messy, or scanned PDFs    | ✅ First character split, then token split      |\n",
    "| Prioritizing speed over accuracy | ✅ Only character splitter                      |\n",
    "| High accuracy, token-aware RAG   | ✅ Only token splitter or both if needed        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86c42f",
   "metadata": {},
   "source": [
    "## Step-by-Step Example\n",
    "Let’s take a sample paragraph:\n",
    "```\n",
    "paragraph = \"\"\"\n",
    "Artificial intelligence is transforming industries. From healthcare to finance, the applications are endless.\n",
    "However, managing large documents and ensuring relevant retrieval remains a challenge.\n",
    "This is where retrieval augmented generation (RAG) comes into play.\n",
    "\"\"\"\n",
    "```\n",
    "### Character Split (RecursiveCharacterTextSplitter):\n",
    "\n",
    "* Roughly splits based on every N characters\n",
    "* You might get something like:\n",
    "```\n",
    "[\"Artificial intelligence is transforming industries. From healthcare to finance, the applications are end\",\n",
    "\"lications are endless. However, managing large documents and ensuring relevant retrieval remains a chall\",\n",
    "\"llenge. This is where retrieval augmented generation (RAG) comes into play.\"]\n",
    "```\n",
    "\n",
    "👎 Issues:\n",
    "\n",
    "* Sentences are broken mid-way\n",
    "* Not token/model aware\n",
    "\n",
    "### Token Split (SentenceTransformersTokenTextSplitter):\n",
    "```\n",
    "# More intelligent splits:\n",
    "[\"Artificial intelligence is transforming industries.\",\n",
    "\"From healthcare to finance, the applications are endless.\",\n",
    "\"However, managing large documents and ensuring relevant retrieval remains a challenge.\",\n",
    "\"This is where retrieval augmented generation (RAG) comes into play.\"]\n",
    "```\n",
    "\n",
    "👍 Benefits:\n",
    "\n",
    "* Each chunk is semantically meaningful.\n",
    "* Aligns with transformer token limits (important for embeddings & prompts).\n",
    "* Less hallucination risk during retrieval or summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cadc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the texts into chunks.\n",
    "# using langchain\n",
    "\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter)\n",
    "\n",
    "# the RecursiveCharacterTextSplitter expects a string.\n",
    "def split_text_into_chunks(extracted_text):\n",
    "    character_text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=20, \n",
    "        length_function=len # Function determining the chunk size\n",
    "    )\n",
    "    character_split_texts= character_text_splitter.split_text(extracted_text)\n",
    "    return character_split_texts  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c76aba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_by_character_split_texts= split_text_into_chunks(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81103414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(character_by_character_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0315c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 \\nDear shareholders, colleagues, customers, and partners,  \\nWe are living through a time of historic challenge and opportunity. As I write this, the world faces ongoing economic, social, \\nand geopolitical volatility. At the same time, we have entered a new age of AI that will fundamentally transform productivity \\nfor every individual, organization, and industry on earth, and help us address some of our most pressing challenges.  \\nThis next generation of AI will reshape every software category and every business, including our own. Forty -eight years \\nafter its founding, Microsoft remains a consequential company because time and time again —from PC/Server, to \\nWeb/Internet, to Cloud/Mobile—we have adapted to technological paradigm shifts. Today, we are doing so once again, as \\nwe lead this new era.  \\nAmid this transformation, our mission to empower every person and every organization on the planet to achieve',\n",
       " 'more remains constant. As a company, we believe we can be the democratizing force for this new generation of technology \\nand the opportunity it will help unlock for every country, community, and individual, while mitigating its risks.  \\nHere are just a few examples of how we are already doing this:  \\n• Leading electronic health records vendor Epic is addressing some of the biggest challenges facing the \\nhealthcare industry today—including physician burnout—by deploying a wide range of copilot solutions built on \\nAzure OpenAI Service and Dragon Ambient eXperience Copilot.  \\n• Mercado Libre is reducing the time its developers spend writing code by more than 50  percent with GitHub \\nCopilot, as the company works to democratize e-commerce across Latin America.  \\n• Mercedes-Benz is making its in -car voice assistant more intuitive for hundreds of thousands of drivers using \\nChatGPT via the Azure OpenAI Service.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_by_character_split_texts[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8f38507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(character_by_character_split_texts):\n",
    "    \"\"\"Splits the text into tokens which the LLMs can understand.\n",
    "   Like subwords.\"\"\"\n",
    "    token_split_text=[]\n",
    "    # define our splitter\n",
    "    token_splitter= SentenceTransformersTokenTextSplitter(\n",
    "    tokens_per_chunk=250, # for llm's token limit account\n",
    "    chunk_overlap=20\n",
    "    )\n",
    "    for text in character_by_character_split_texts:\n",
    "        token_split_text.extend(token_splitter.split_text(text))\n",
    "        \n",
    "    return token_split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1590cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text into token chunks\n",
    "token_split_texts= split_into_tokens(character_by_character_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bac932da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_split_texts)\n",
    "# this is more than the character split texts\n",
    "# because the token split is more granular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198cc9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build our embedding model and push in vector db\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def build_embedding_model():\n",
    "    model_name= 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    model= SentenceTransformer(model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce4219",
   "metadata": {},
   "source": [
    "If token_split_texts is a list like:\n",
    "\n",
    "`token_split_texts = [\"chunk 1 text...\", \"chunk 2 text...\", \"chunk 3 text...\"]`\n",
    "\n",
    "Then calling .encode(token_split_texts) will return:\n",
    "\n",
    "```\n",
    "[\n",
    "  [0.123, 0.456, ...],  # embedding for chunk 1\n",
    "  [0.789, 0.321, ...],  # embedding for chunk 2\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc332e",
   "metadata": {},
   "source": [
    "🔍 How Many Rows Are Created in ChromaDB?\n",
    "Answer:\n",
    "➡️ One row per chunk, not per full document.\n",
    "\n",
    "So if your token_split_texts contains 53 chunks, you'll store 53 rows in ChromaDB, each with:\n",
    "\n",
    "* A chunk of text\n",
    "* Its embedding\n",
    "* A unique ID\n",
    "* Metadata (like source)\n",
    "\n",
    "🧭 ChromaDB Structure (Diagram)\n",
    "| ID   | Document (Chunk Text)       | Embedding    | Metadata                     |\n",
    "|------|-----------------------------|--------------|------------------------------|\n",
    "| \"0\"  | \"Artificial intell...\"      | [0.12, ...]  | {\"source\": \"microsoft_pdf\"}   |\n",
    "| \"1\"  | \"From healthcare...\"        | [0.34, ...]  | {\"source\": \"microsoft_pdf\"}   |\n",
    "| \"2\"  | \"However, managing...\"      | [0.98, ...]  | {\"source\": \"microsoft_pdf\"}   |\n",
    "| ...  | ...                         | ...          | ...                           |\n",
    "Each row = 1 chunk = 1 embedding = 1 retrievable item in RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a67b73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and store embeddings\n",
    "import chromadb\n",
    "def build_embedding_and_store_in_vector_db(token_split_texts):\n",
    "    # get the embedding model\n",
    "    embedding_model= build_embedding_model()\n",
    "\n",
    "    # create the chroma Client\n",
    "    client=chromadb.PersistentClient(\n",
    "        path=\"microsoft_pdf_embeddings\", # folder for db\n",
    "    )\n",
    "\n",
    "    # create the collection\n",
    "    collection= client.get_or_create_collection(\n",
    "        name=\"microsoft_collection\",     # name of the collection\n",
    "    )\n",
    "\n",
    "    # get the embedding of each chunk\n",
    "    embeddings = embedding_model.encode(token_split_texts)\n",
    "    \n",
    "    # add the embeddings to the collection\n",
    "    collection.add(\n",
    "        documents= token_split_texts,  # the texts to be added\n",
    "        ids= [str(i) for i in range (len(token_split_texts))],  # unique ids for each text\n",
    "        embeddings= embeddings,  # the embeddings of the texts\n",
    "        metadatas= [{\"source\": \"microsoft_pdf\"}] * len(token_split_texts)  # metadata for each text\n",
    "    )\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f52839",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection= build_embedding_and_store_in_vector_db(token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfaea653",
   "metadata": {},
   "outputs": [],
   "source": [
    "count= collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4a3af72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5369850",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What was the total revenue for the year?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde64beb",
   "metadata": {},
   "source": [
    "### Hypothetical Document Embeddings.\n",
    "* Ask an LLM to hallucinate over a query.\n",
    "* Take that query + hallucinated answer and get relevant texts from the collection.\n",
    "* You can then feed this entire thing into the llm to give you a perfect response. [OPTIONAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06ab4907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\think\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\think\\anaconda3\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\think\\anaconda3\\lib\\site-packages (from ollama) (2.11.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\think\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9805af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "def get_hallucinated_query_response(query, model_name='gemma3n:latest'):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful expert financial research assisttant.\n",
    "    Provide an example answer to the given question, that might be found in a document like an annual report.\n",
    "\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt,\n",
    "                }\n",
    "            ],\n",
    "            options={\n",
    "                'temperature': 0.6, #[ closer to 0: Deterministic]\n",
    "                'max_tokens': 200,  # length of response\n",
    "                'top_p': 0.8, # Filters the model's vocabulary to the top probable tokens.\n",
    "            }                 # Range: 0.1 (strict) to 1.0 (broad).\n",
    "        )\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a311c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_hallucinated_response= get_hallucinated_query_response(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f505340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Total revenue for the year ended December 31, 2023, was $125.7 million. This represents a 5.2% increase compared to $119.3 million in 2022. The growth was primarily driven by increased sales in our core product lines and expansion into the [mention a specific new market or product area, if applicable].**\\n\\n\\n\\n**Explanation of why this is a good answer for an annual report:**\\n\\n*   **Directly answers the question:** It clearly states the total revenue figure.\\n*   **Specifies the period:**  It includes the date the revenue covers (year ended December 31, 2023). This is crucial for clarity.\\n*   **Provides context:** It includes a year-over-year comparison, showing the growth or decline.  This is important for investors to understand the company's performance trend.\\n*   **Highlights key drivers:** It briefly explains *why* the revenue changed, pointing to specific factors like product line performance or market expansion. This adds valuable insight.\\n*   **Uses professional language:** The language is formal and appropriate for a financial document.\\n*   **Includes currency:** Specifies the currency ($).\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_hallucinated_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842a9de",
   "metadata": {},
   "source": [
    "Next pass this joint answer: query+ response into the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53b61963",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_query= f\"{query} {llm_hallucinated_response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3064228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jointQuery_responses(llm_hallucinated_response,query, collection):\n",
    "    # in chroma you dont need to build the embedding for the query\n",
    "    joint_query = f\"{query} {llm_hallucinated_response}\"\n",
    "    \n",
    "    results= collection.query(\n",
    "        query_texts=[llm_hallucinated_response],  # the query text\n",
    "        n_results=5,\n",
    "        include=[\"documents\", \"embeddings\"]  # what to include in the results\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fae5731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_query_retrieval_answer= get_jointQuery_responses(llm_hallucinated_response, query, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef80f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['136', '121', '120', '186', '127']],\n",
       " 'embeddings': [array([[ 0.00314847, -0.0564224 ,  0.03329218, ..., -0.11772352,\n",
       "          -0.0172887 ,  0.05966147],\n",
       "         [-0.02402674, -0.06448872, -0.01477951, ..., -0.06723693,\n",
       "          -0.00935987, -0.01644639],\n",
       "         [ 0.02184383, -0.03202321, -0.05222332, ..., -0.08729147,\n",
       "          -0.02081233, -0.00172158],\n",
       "         [ 0.00563767, -0.00375291,  0.03884898, ..., -0.0891605 ,\n",
       "          -0.04481906, -0.0374296 ],\n",
       "         [ 0.01764905, -0.03460781,  0.02327529, ..., -0.14289753,\n",
       "           0.02588371, -0.01848453]])],\n",
       " 'documents': [['fiscal year 2023 compared with fiscal year 2022 research and development expenses increased $ 2. 7 billion or 11 % driven by investments in cloud engineering and linkedin. sales and marketing ( in millions, except percentages ) 2023 2022 percentage change sales and marketing $ 22, 759 $ 21, 825 4 % as a percent of revenue 11 % 11 % 0ppt sales and marketing expenses include payroll, employee benefits, stock - based compensation expense, and other headcount - related expenses associated with sales and marketing personnel, and the costs of advertising, promotions, trade shows, seminars, and other programs. fiscal year 2023 compared with fiscal year 2022 sales and marketing expenses increased $ 934 million or 4 % driven by 3 points of growth from the nuance and xandr acquisitions and investments in commercial sales, offset in part by a decline in windows advertising. sales and marketing included a favorable foreign currency impact of 2 %.',\n",
       "   'in the first quarter of fiscal year 2023, we made updates to the presentation and method of calculation for certain metrics, most notably expanding our surface metric into a broader devices metric to incorporate additional revenue streams, along with other minor changes to align with how we manage our businesses. commercial our commercial business primarily consists of server products and cloud services, office commercial, windows commercial, the commercial portio n of linkedin, enterprise services, and dynamics. our commercial metrics allow management and investors to assess the overall health of our commercial business and include leading indicators of future performance. commercial remaining performance obligation commercial portion of revenue allocated to remaining performance obligations, which includes unearned revenue and amounts that will be invoiced and recognized as revenue in future periods',\n",
       "   'additional information on our reportable segments is contained in note 19 – segment information and geographic data of the notes to financial statements. metrics we use metrics in assessing the performance of our business and to make informed decisions regarding the allocation of resources. we disclose metrics to enable investors to evaluate progress against our ambitions, provide t ransparency into performance trends, and reflect the continued evolution of our products and services. our commercial and other business metrics are fundamentally connected based on how customers use our products and services. the metrics are disclosed in the md & a or the notes to financial statements. financial metrics are calculated based on financial results prepared in accordance with accounting principles generally accepted in the united states of america ( “ gaap ” ), and growth comparisons relate to the corresponding period of last fiscal year.',\n",
       "   'years to six years. this change in accounting estimate was effective beginning fiscal year 20 23. based on the carrying amount of server and network equipment included in property and equipment, net as of june 30, 2022, the effect of this change in estimate for fiscal year 2023 was an increase in operating income of $ 3. 7 billion and net income of $ 3. 0 billion, or $ 0. 40 per both basic and diluted share. foreign currencies assets and liabilities recorded in foreign currencies are translated at the exchange rate on the balance sheet date. revenue and expenses are translated at average rates of exchan ge prevailing during the year. translation adjustments resulting from this process are recorded to other comprehensive income. revenue product revenue and service and other revenue product revenue includes sales from operating systems, cross - device productivity and collaboration applications, server',\n",
       "   'statements for further discussion. refer to the non - gaap financial measures section below for a reconciliation of our financial results reported in accordance with gaap to non - gaap financial results. 31 fiscal year 2023 compared with fiscal year 2022 revenue increased $ 13. 6 billion or 7 % driven by growth in intelligent cloud and productivity and business processes, offset in part by a decline in more personal computing. intelligent c loud revenue increased driven by azure and other cloud services. productivity and business processes revenue increased driven by office 365 commercial and linkedin. more personal computing revenue decreased driven by windows and devices. cost of revenue increased $ 3. 2 billion or 5 % driven by growth in microsoft cloud, offset in part by the change in accounting estimate. gross margin increased $ 10. 4 billion or 8 % driven by growth in intelligent cloud and productivity and business processes']],\n",
       " 'uris': None,\n",
       " 'included': ['documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': None,\n",
       " 'distances': None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_query_retrieval_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20e12900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in c:\\users\\think\\anaconda3\\lib\\site-packages (0.5.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\think\\anaconda3\\lib\\site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\think\\anaconda3\\lib\\site-packages (from umap-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in c:\\users\\think\\anaconda3\\lib\\site-packages (from umap-learn) (1.7.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\think\\anaconda3\\lib\\site-packages (from umap-learn) (0.59.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\think\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in c:\\users\\think\\anaconda3\\lib\\site-packages (from umap-learn) (4.66.5)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.42.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\think\\anaconda3\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\think\\anaconda3\\lib\\site-packages (from scikit-learn>=1.6->umap-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\think\\anaconda3\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75622f49",
   "metadata": {},
   "source": [
    "Now since the embeddings are high dimensionality vectors. And to visualize them we will be using UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aeaf96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = collection.get(include=[\"embeddings\"])[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bbf61ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.48643304e-02, -2.65765302e-02,  5.08678444e-02, ...,\n",
       "        -3.12455930e-02, -2.34171394e-02, -5.24429269e-02],\n",
       "       [-9.82296467e-02, -6.92604622e-03, -1.80437695e-03, ...,\n",
       "        -9.67107937e-02,  4.92179208e-02,  2.39097187e-03],\n",
       "       [-2.78818402e-02, -4.32330444e-02,  1.78645190e-03, ...,\n",
       "        -9.36608389e-02,  7.30100870e-02, -3.61429714e-02],\n",
       "       ...,\n",
       "       [-4.16572243e-02, -3.62805836e-02,  4.20238674e-02, ...,\n",
       "        -6.94045499e-02, -6.69304579e-02, -9.39283520e-03],\n",
       "       [-9.90765548e-05, -1.64379608e-02,  2.47890744e-02, ...,\n",
       "        -3.96450311e-02, -4.84677218e-02,  6.33781170e-03],\n",
       "       [-9.09882039e-03,  1.83823369e-02, -2.10490432e-02, ...,\n",
       "         7.12936511e-03, -2.07488686e-02, -5.88578507e-02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e52cf",
   "metadata": {},
   "source": [
    "```\n",
    "[\n",
    "  [0.11, 0.98, ..., 0.21],  # Embedding for chunk 0\n",
    "  [0.10, 0.97, ..., 0.25],  # Embedding for chunk 1\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb5adb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efceb32",
   "metadata": {},
   "source": [
    "* umap.UMAP(...) initializes the dimensionality reduction algorithm.\n",
    "    * random_state=0 ensures reproducibility.\n",
    "    * transform_seed=0 ensures consistent transforms for new points.\n",
    "* .fit(embeddings) learns a 2D map from high-dimensional vectors.\n",
    "* umap_transform now holds a trained projection model to map embeddings → 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "988b1885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\think\\anaconda3\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6622ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_dataset_embeddings = umap_transform.transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c7987",
   "metadata": {},
   "source": [
    "projected_dataset_embeddings is now:\n",
    "```\n",
    "[\n",
    "  [1.02, 4.33],   # 2D X,Y position of chunk 0\n",
    "  [1.55, 4.10],   # 2D position of chunk 1\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c500612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= build_embedding_model()\n",
    "retrieved_embeddings = joint_query_retrieval_answer[\"embeddings\"][0]\n",
    "original_query_embedding = model.encode([query])\n",
    "augmented_query_embedding = model.encode([joint_query])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f90160",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_original_query_embedding = umap_transform.transform(original_query_embedding)\n",
    "projected_augmented_query_embedding = umap_transform.transform(augmented_query_embedding)\n",
    "projected_retrieved_embeddings = umap_transform.transform(retrieved_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c558f40a",
   "metadata": {},
   "source": [
    "| Variable                        | What it contains                          | Purpose                                   |\n",
    "|---------------------------------|------------------------------------------|-------------------------------------------|\n",
    "| `embeddings`                    | All document chunk embeddings (384D)      | Raw data                                  |\n",
    "| `umap_transform`                | 2D projection model from UMAP            | To reduce dimensions                      |\n",
    "| `projected_dataset_embeddings`  | All chunks in 2D space                   | For gray scatter plot                     |\n",
    "| `retrieved_embeddings`          | Top-5 matched doc embeddings             | Green circles in visualization            |\n",
    "| `original_query_embedding`      | Embedding of user's query                | Red \"X\" marker in plot                    |\n",
    "| `augmented_query_embedding`     | Embedding of HyDE query                  | Orange \"X\" marker in plot                 |\n",
    "| `project_embeddings(...)`       | Applies `umap_transform` to map to 2D    | Used for visualization                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0306f0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGZCAYAAAAUzjLvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHJklEQVR4nO3dB5gV1fn48Rd2EUVEaRbAqCihKIugohGEYECNSlysscSGvSQxahL/pmt6ojHGqPmJRk1BTRDF3sESKwhEUYHEhhoVVFBRYbn/5z046+zszNyZe6fP9/M8y7K3zJ077bxzznvO6VCpVCoCAABKq2PaKwAAANJFMAAAQMkRDAAAUHIEAwAAlBzBAAAAJUcwAABAyREMAABQcgQDAACUHMEAAAAlRzAQk3/84x/SoUMHue6669o9N2zYMPPcnXfe2e65rbfeWkaMGNH6t77utNNOi2y9XnvtNfnRj34kTz/9tOTZI488Yr7Hu+++2+65LbfcUvbdd9/Y1+GPf/yj/PnPf675/R9++KH5Dg888EDNy3jxxRfNMVLPeuAzn3zyiZx00kmy2WabSUNDg2y//faxft7f/vY3+d3vfue5X3/zm99I2axatUouu+wyGT16tPTs2VN69Ohhzufnnnsu7VUrNIKBmHzxi180J/P999/f5vFly5bJ/PnzZf3112/33Kuvvir/+c9/ZNy4cbGtlwYDP/7xjwsRDOj3cAsGkhJFMKDfoZ5gANG69NJL5fLLL5dzzz1XHnroIbn22mtTCQbKbMmSJfK9731P9thjD3NTdckll8gzzzwjEyZMkBUrVqS9eoXVmPYKFFWvXr1ku+22a3ehnzlzpjQ2NsrkyZPbBQPW33EGA4D9DkwDVj0esda///1vWW+99SKtjVu5cqVZJoIFyJtssom5KerWrVvr4506dZKDDjpIHn/8cfnSl76U6joWFTUDMdJC/fnnn5fXX3+99TENDnbaaSfZe++95amnnmoT6epzWjW52267tVuW3qEMHjxYunTpYpoZbrnlljbPL1q0SI455hgZMGCAeU3fvn1l4sSJphbC+dlKX6sFgf5oVbWb5cuXm4Li17/+detjb7/9tnTs2FE23HBDWb16devjX//616V3795izXt19913y3777Sf9+vWTddddV7bZZhs58cQTzfvt3nrrLTnhhBNk8803l86dO5tljBo1Su655x7P7arre/bZZ5v/b7XVVq3fwxl43XHHHabJRS/EgwYNkiuvvLLdst544w2zXrqe66yzjlme3q3bv5sbbYrQuxUN7qzP18csL7/8shxxxBGy8cYbm++l++63v/2trFmzprUaWL+r0s+zlnH00UcH3p9h6LbR5etxdOaZZ5rl6Xrp5yjd3nqR1Quwfp7ug3vvvbf1/dOnTzfvtz9mv5vW5+bNm9f62JNPPilf+cpXTBWv7v/hw4fL9ddf3+Z9Wqti1Z6dfPLJJoDWauH999/f1GDZeR2nus2tbVbvPtXPuOKKK0zhbe0Pq+bno48+knPOOccsS5ep2+/UU09tVzNlNVFNmzbNfGf97vrZXrWHt956q7z00kutn6c/ThdccIH53K5du8oXvvAFefTRR9u9Jsj2dtJzVY+vPffcs91z77//vjnH9TvarwdnnXVWm23wzW9+Uz744IM279U7+TFjxphjX2tAhw4dKr/61a9M8On8/nrDNGvWLNl1113NcXfsscea89UeCKgFCxaY33qMICY6ayHiceONN2rJWPnb3/7W+tjQoUMr55xzTmXFihWVxsbGyq233tr63FZbbVXZaaed2ixD37/llltWRo4cWbn++usrt912W+WLX/yiee/ixYtbXzdz5szKmWeeWfnHP/5h/q+f3dzcXFlvvfUqzz33nHnNe++9V7nqqqvMMr/3ve9V/vWvf5mfV155xfM77LLLLpU99tij9e+pU6dW1l133UqHDh0qDz/8cOvjgwcPrhx88MGtf1966aWVn//855Wbb77ZrM/VV19dGTZsWGXgwIGVTz75pPV1e+65Z6V3796VP/3pT5UHHnigMn369MoPfvAD8zledH1PP/108z2mTZvW+j30+6ktttii0q9fv8qQIUMq11xzTeXOO++sHHTQQeb1ui6W119/vbL55pub119++eWVe+65p3LeeedVOnfuXDn66KMrfmbPnl3p379/Zfjw4a2fr4+pN998s9K3b1/zvS677LLKHXfcUTnttNPM55988snmNR999JF5XB+bPHly6zIWLVoUeH+q//73v2YZul/93H///eZ1ul4HHnig2S+33HJLZenSpZVrr73W7E9dvm7PGTNmVPbdd99KQ0OD2SZq1apVlY033rhy+OGHt1u2HpsjRoxo/fu+++6rrLPOOpXddtutct1115nvqdvTuZ7WsajbUfen7qcrrrii0r1798q4cePafIa+7oc//GG7z9Z9d9RRR0WyT3X777333mYbW/tD9+WaNWvMcarn3Pe///3KXXfdVfnNb35TWX/99c3+131pX5/NNtvMfKcrr7zSbPfHH3/c9fOeeeaZyqhRoyqbbrpp6+fpj32/6rm/1157mfNCf/T6odvn3XffDb293Vx00UVm37/wwgttHr/kkkvM+3Ud1QcffFDZfvvtK7169apccMEFZrvqezfccMPK7rvvbraR5YwzzjDnv66HrtuFF15o3nfMMce0+YyxY8dWevToYfbXxRdfbLaV/fy06LGq3+/YY4/1/S6oD8FAjJYtW1bp2LFj5YQTTjB/v/322+bE05PEuoieddZZ5v8vv/yyOfm+/e1vt1mGPrbJJptUli9f3vrYG2+8YZarha2X1atXm0J3wIAB5uS0PPHEE4EuEhYNGvTiaF3wjjvuOHNxampqqvz4xz82jy1ZssQsUwt0N3qh0MLkpZdeMq+76aabWp/r2rVr5Zvf/GYlrF//+tdmWXrRdNILsgYs+nmWlStXmgvPiSee2PqY/l8/3/46pRd6+4XQy7bbbmsuaE7f/e53zfsfe+yxNo9rIKD7//nnnzd/v/XWW56FXND9GTYYGDNmTJvH9SKv22XixIltHm9paTHBmx6jlm9961vmWLAXRM8++6xZrl7MLYMGDTKFpO5zOw0wtKDUZduDgVNOOaXN6371q1+Zx7VgDxsM1LtPdVlayNtZQZuul50WvM7jXtdHgyhrH1ezzz77mPc4WftVC3/d9xYNLPTxv//976G3txu9rmywwQaVb3zjG20e10DaHpDptUavOXr9sNNgVddHb1Lc6GfremlQrttFr4kWPXf0vffee6/n+ulyO3XqVDnggAPafT9Ei2aCGHXv3t1U6VvV11qlrM0AWgWrxo4d25on4JcvoI9tsMEGrX9rm5pWwWn1okWrQH/2s5/JkCFDTBWeVu/r74ULF7ZWsdVCq4612lQT9qzqZE3kGT9+vGkKsB5T+pjlzTffNFnZWv2v66JtfltssYV5zr4+I0eONFWx559/vqn+dFYl1kqzwD/3uc+1/q1Vp5///OfbbDNtatFt26dPH7P9rJ8vf/nLrfurFvfdd5/ZD/rd7LQ6W8s1fb6auPbnAQcc0OZv3a+a1HrUUUe12QbanLHXXnvJE0880VoNrFW4eizYe8hcddVVprnhsMMOM39rs4NmfR9++OGt38P60aYxbTLTpjM7rd62a2pqMr/t+yqoOPaptb+czRHahq3V4M6mE11/PdaisM8++5hrhn3Z9m1Ty/a20+uKNkfpOWjtZ/2+zz77bJu8Cd2uWqWv55X9M7SJwdlEN2fOHLNPtclH113P/SOPPFJaWlrkhRdeaHeN3H333V3XTc+V4447zjR5/P3vfye3JWYEAzHTC5OeANoGqgX+DjvsYNr+rGBAT5z33nvPPKcHu3ancdKTykkvwHphtnzrW9+S73//+9Lc3CwzZsyQxx57zFzINRixvy4sqy1PC3y98GhbtxUM6Gdo26I+179/f9OWqLQg0UxgbTf99re/bS6WmvhjtXXa10cLFi2ItK1W20O1zVMvHNruW48g2+x///uf2VZ6sbL/bLvttuZ5Z35DUEuXLjVd05y0gLKeryau/elcL90G6sADD2y3HX75y1+aC7IGC0q3i+acaACg9OL+l7/8xeSG6H6zL0/blp3LO+WUU1y3q3Nf6X5StXzPOPap7i89N60cD4sWgptuumm7/em272tVbdvUsr2dTj/9dJO79Ne//tX8/Yc//MHkW+h+tejnaE6I8zM0mNBjxPoMzZXRnCftEXDRRRfJgw8+aI5bzSOwr3eQbaXXRb1u6rVEPwvxItRKIBjQBCCNnPVHo3WLVfBrAo2V3GcFCmHpRVkLUb2btNOTdKONNqp5/fVuVNdTC3y9QOjFTxOCtPBXut5a2Nv79WtG9ty5c83dhhb0FitZzU4TgrRrlf7oheTmm2+W7373u6ZmQRMA46SfrXdaP/3pT12ftwrvWi7g9qRRi5UUFyQJKq796UxQs9bl4osvll122cX1PVoTZdG7SC1ktHZCM771e+pjzuVpsp0mAroZOHBg6PXWQvDjjz9u97izII5jn+r+1LtgTXa1BwRaCGrQaiXlWtySAOMSxfbW5F6tOdECW3/rOahJj/YaCf0cTexzS8K1r4cmmmoNg94IWDWByqsrc7VtpetuP/4QH4KBmGlWrZ5U2l9Ws881q9ai2bpa7Xb11VebO26rqrUWelJZdw0WzVTWCF1P9nruurQWQC82ehdgNQVo9agWHlqIaCFnbyKwTnDn+mj/bT9ara9VkxpcPPzww76vrefu0aIBzG233WYGetLqyrCcNQ32ppWf//znMnv27DYDSF1zzTVm21hNQX7fIej+rJc2WWlw4awW9nLooYeaWgsN9DQY0IxyvXOzX7w1Q12DQWcgUw/N0rf3VrCqs7VmKsp96kb3p563GqCdccYZrY//85//NAVfPV3dvI6hoKLa3t/4xjfMftTgXa9Xxx9/fLvtqsvXwMiqAXTjdu5r0PR///d/oddJj0sGGkoOwUDMtIuMFggaMWuXPCtfwKJNBdagI/WML6Anq16gtQud3hlpt0XtEqh383Z6kdQIX6sEtbub1kTo3ZLfHZNe7LRKWAtpDVwsGgD88Ic/NBcAe7ufroN+jt7h64VAq5C16tbKMbBXA+p31iBI36PBhlYpao2A112ORWsnlFZF6gVMqxH1wmjPrajmJz/5iVknbQrRrpH6fu1CpoGZFig6Cppz+znXYerUqaapQ2tKNC9BH9MCQwt+be/Vz9A7JC3IdZAi7UJntSfruupzN910k9nGup30DsvqnhZkf9ZL978GdLoNtTlAmws0H0XvgrWA0d/addB+gZ40aZJZN+1Wp9XTelw7gz69w9T2ZG1n14BBl621CRog3XDDDaHX82tf+5ppNvnBD35gzhkNXrQ6WwPqKPepG20W0+/yne98x3Sv03NYAxM99rU9W9etVnq86F20bmNtQtRtueOOO4ZaRhTbW7+j5qdoc6XVJdZOuxBq8KM3N3p86zGpzYFam3fXXXeZ7qo777yzWY7WJmrQqE2Euu31u73zzjuht43mReh1RPe5/iBmESckwoX2ENBNveOOO7Z7TrsL6XPadUYzu530uVNPPbVqFvU777xjuqhp968uXbpURo8eXXnwwQdNxq4z410zkTUDWbN0g2Sza28A7Rqkr9WeAxbtWqiP2buV2bPMJ0yYYDKVtSuUdu2zekxYn6c9FE466STTM6Fbt24mU127HurzbtvCSbto9unTx2Q563I1Y97aNpql7eS2LTSj/+tf/7rp1qnbQzPrd9hhh8q5555bef/9930//8UXXzTdLvU76ufbs8I1m/2www6r9OzZ0yxXv5f2gHBmdmsXLc0E165vugxrnwbdn2F7E9xwww2uz2uXLt1m+v11fbULov7t9nrtWqfL0h9nlzTL3LlzTVdTXX9dnnaf0y5o2tXSYvUmcGaoW+tq7U/18ccfm/NIu6HpcaLb4Omnn253HtS7T916E1i9Ub7zne+Yz9Nlapa+9g7R/WTndex50ex67eq50UYbmZ4m1iXZ2q96zDi5nbNBtnc1P/rRj8yyH330Udfnddtp7yI9lvV6pd0KtbeD9m7RHk4W7ZqqPVG0R48eR2effXbl9ttvb7dPdR9qjxwv1jYI0tsG9eug/8QdcAAAsk1rJLSWT2vnUD40EwBASWmzhyb8atdBbYq68cYb014lpIRgAABKSnMKNG9HEwM1B0K7sqKcaCYAAKDkGHQIAICSIxgAAKDkCAYAACg5ggEAAEqOYAAAgJIjGAAAoOQIBgAAKDmCAQAASo5gAACAkiMYAACg5AgGAAAoOYIBAABKjmAAAICSIxgAAKDkCAYAACg5ggEAAEqOYAAAgJJrTHsFiu7VV1+VpUuXSs+ePaVfv35prw4AAO0QDMTo7rvvlkceeaT171133VUmTJiQ6joBAOBEM0GMNQL2QEDp3/o4AABZQjAQE20aCPM4AABpIRiIieYIhHkcAIC0EAzERJMFNUfAbtSoUSQRAgAyp0OlUqmkvRJFRm8CAEDWEQwAAFBydC3MEGoRAABpIBjISBAwc+ZMWbRoUaAxCQgaAABRIhjI2MBEFn1s8ODB7Qp7BjICAESNYCAmQe7e3QYmstP329/rNZBRY2OjDBgwgFoCAEBNCAZiEPTuvdoARM4xCbxeP2vWLPNDLQEAoBaMM5DiMMR+AxC5jUlQbcAihjsGANSCYCDhYYi1sJ47d6757TYwkVb3T548WcaPH99uGW6vD/r5AAB4oZkgwWGIvZoPNFEwaO8A6/ULFy40TQNBPx8AAC8EAxGz7t7thb5W+Su35gOrx0CY5D/r9atXr273OSQRAgDCYgTChHoTaNPA9OnT272uublZhg0bFng5YZ8HAKAaagZi4rzbr2UWwyC9EqrVKljBQktLizQ0NBA0AADaIRhIufkgzBgEVrOCClIb4DWgEV0QAQB2BAM1qLVqPkyyoFevgKDDFvsNaOQ1uiEAoJwIBkKqdzjgoMmCXs0H9kDAr2Cv1sVQeyMQDAAAFOMMxDSgUNDlWWMOOHmNQeDGreCv1sVQuyVqYAMAADUDEQ0oFPYuO0gNg7NZwbqjD1Lwu+UoONFcAABQBAMh+PUICJNH4Jcc6Hyvs1khTBKiPZh48cUX5emnn44kkAEAFAvBQAhud9tNTU2Bk/qiqGEIO2KhFUzoa92CAUYsBAAQDIRkL4wXL14s8+bNC139XsuYA3ZhRyy03hOmVgEAUB4EAzWwClC3EQW9svWdzQhpFMxhaxUAAOVAMFCjMLMDRjFBUVRqqVUAABQbwUCNqlXpW90AqyULUjADANLGOAM1chsHwK3K3y9ZEACALKBmoA72qn6viYDqTRZMGrMgAkD5MIVxApw5A1pzMH78+MwV+G65DSQcAkDxEQyU7I7bK5lR12/KlCm+72W2QwAoJpoJEhJlsmCtgYVfMmOQHAaGLwaAYiIYKNGsiX7JjEFzGBi+GACKh94EJZo10S+Z0a93RJBlAADyi5qBEs2aWG3kQ20CaGxsbB0nYcGCBQxfDAAlQDCQI1F0U/Qa+dDZ/LB69WqGLwaAkqA3Qc7E0U3RqyfB5MmTCQAAoASoGcgJqweB3qlHfbdeb/ODff2oQQCA/CEYKHgPgiSaH+JePwBAvOhNUPAeBF7LnDt3busy3HoSBE0WjGP9AADJomYgg+xV7lFU4Qe5i681WTDq9QMAJI9gIGOchfXQoUMj6+8fZDrlsAV43iZiAgC0RzNBhrgV1vPnz28XENTa3z+O6ZTraWIAAGQDNQMZ4lUob7311jJy5Mg2UyVr4JCVu3jGIwCAfCMYyJBqhfW///1vWbRoUc1Z+9VGIMzKREwAgGQx6FAOBhXSXeRsPqhnYCDGBAAA2BEMZJC9sFZuowNampubZdiwYQmuHQCgaGgmyCB7lbuOB+CHrH0AQL0IBmJWb5W8X2FP1j4AIAo0E8QoqmF6ncvR6YXHjBlDIAAAiATBQEyingmQpD8AQFxoJohJ1MP00nUPABAXRiCMCcP0AgDygmAgJm7D9DY1NXF3DwDIHIKBGGmyoH1egXnz5plkQMTLOUUzAMAfOQMx0sJIJxrymiUQ0Zs2bVqbbV5rDw4AKBNqBmIUxyyBCB4IWMEXNQQA4I9gIGdJhFSBB6+FsRB8AYA/mgki4jYOQNSzBEY1iFER+RX49OAAAH8EAxHwK6Q1P6CxsbF15MBaAwENNpwzF5J/UL3AD9uDg8GdAJQRwUCd/ArpBQsWtHlu9erVNRcwUQ9iVDRutTAaCEyaNClwwU/NC4CyIhiok1chvXDhwkjv5BnEqDotuHX7Brmzdxb82gWUnh8AyooEwjqFLYxrTWZzG8SIWQujq80h+RBAmVEzUCevJEHND5g1a1akd/Jh7nzLKGg1f5gCnpoXAGVAMBABr0I6yp4EFiYsqj/B0quAdzYVUPMCoCwIBiLiVkhzJ5+cMAmWXrU548ePl5EjR7K/AJQOwUDMuJNPRtgES69Ajf0FoIw6VCqVStorAcSRM2Dd7QMA/BEMoFCyNGhQltYFAPwQDMCg4IoWsycCyBNyBlD6kfeiDoS8Zk9kAKPiHiME08g7goGSK/ucB1EHQtVmTyzDNi3bMeL1vDNAIGBAlhEMlFyZ5zyIIxBi9sRyHSNez69YsaJNUNinTx957bXXSlv7huxjOOKY6cVi7ty55ncWlXnOA79AqFbVtlvWjweEO0a8nnfWDtkDAStg4BhAllAzUNC2+KBVkl4D8BS9ViCuQEi32zbbbCOLFi1q99ydd97ZpgDg7jD/x0g9x0oZat+QHwQDBWyLDxuElHWkxLgCobFjx7oGA847waiPB9qkkz9GvKbOnjdvXtVl2wMJ9h3SRjBQsLb4WoOQso68F0cg5FZAeInqeCh7j5A0jxG357t27dpmfzhzBjSgUNpktHjxYt9uqAQKSALBQMHa4sucEFirOAIhewGxbNky1xksozoeyt4jJAvHiPN5twDBXqgvWLBApkyZ4ros+74jyENSSCCMiXV3aJdEW3yZEwKzRvf1sGHDzHTWbrQ6OYrjIY5ESES3/+1NCvq3qlZrpPvOK8gj8RBxoGYgRmm0xZc5ITCrvNqVJ02aFMnyCQDzJUiQ1tLSInPmzPF8P+czosZwxAVFO2O59kmYSZo4NupT7/bT93s1EajevXvLW2+95fn85MmT2W+IHMEAUJDCJ8jraIOuT1Tbz7mcagGAhZk4EReCAbTijjF7oiy8ve5IudNMZ/tZ55s2CcyYMcP3tSNGjJC+fftKQ0MD5ydiQc4ADO4Y8zkUbpjgjZ4m9Yl6+1k9ELR7YTWrVq1qEzBwfiJqBAMZltSdOl3T8lf4aNe0sMEbiYb1iWv7VXu/2yBGnJ+IGsFARiV5p84dYzZ5FRJarVzrwFL0NKk98I5r+3n1Nunfv79ZH10vtxENoz4/aSYsN4KBDEr6Tp07xmzyKny03dhNkMKhrENPRxV4x7X9vJar1wIdtCru85NmQhAMZFDSd+rcMWaX10h29RQOZR16OqrAO+rtZ78jtwYlciug7aI8P2kmhCIYyKA07tS5Y8wuZ+FD8FacJjKvO3K3AlqNGTPGjGgZ5bqlvQ2QDQQDGZTWxZ47xvxIIngrQxtymk1kfnfkXgV0jx49It8XNBNCEQxkFHfqSDN4K0sbcq2BdxSBkt8deZIFtK6/c1ZF/dvte5UhQCwrgoECXew5URGFsrUhhw28owqU/Ar8JGsHdX/bAwGlf+vj9s8rS4BYVgQDBcGJiqiUsQ05aOAdZaBUrcBPqnYwyP4uW4BYRgQDBRD1SHUoN9qQkwuUqhX4SeTxBNnfZQwQy4ZgoACiHqkO2RZ3cEdvhWgDpWr7K+3E3SD7228ALB1OmRuN/GOiogJPoDJx4kTXCVCYmCa/kmwOChJ0+L2mqDVSYaaLzlPzXbX95fwuOnHSkiVLcvHdUB3BQIEvUDot6vTp09u9trm5uc3gJsiHrM066FfQ5akQjDNQytL+ikK1mRbz/N3KjmaCFEV55xTHSHXIliy12/rlqVj/d3uuKAVFkKr9LO2vqFSbaTHP363sCAZSEsedEyPVlbu9Oslqeb+Czu89ZTr2ipyIWeTvVlYEAylIspsOgxdlQxQFtV9wl3S1fC2FQdkKiqIE4/ZjV1n/L8J3w2cIBkoyEREnaXqiLKi9moOSrpavVtBlraBIK5kx78G432RJuo81RyCv3w1tEQykgCq28oijoHYGd2m1TfsVdPbnNNlMp112jmiXVEHtLNC22WYbGTt2bGKFV16Dca/JkpzHMcnIxUAwkIKiVB+iuiQK6rSCyyD956uNcxF384ZbgbZo0SLzo5+V57v2uPnlf1gWLlzI9isIgoGU5L36ENkpqNMILoMU4kFGxoy7ecOvQNPPKnL3x3oFOUZnzZrV+n+2X751THsFykwveFrFRiBQXFZBbRdHQa0XYW2/1TEk9LfXIDhR8CrEnV1Zq/U4qKVHQlhhgi6371BmbseuH7ZfvlEzABSkFiiptumgTR/VakXSqjXxU7buj2GPXaX/X7ZsWZtaAQvbL7+oGQASUKRaoKCFeLVakaRrTTRxsBqSeP2PXev/AwYMcH0t2y+/GI4YQKzj81dLNIyrN4Hbcu2POZMb/b4D6jsGkH0EAzlX1MlgkH1ZPvaC9lLI8nfIA+f2Y3vmF8FAjhV9MhigFkWcICgPuB7lGzkDORU0o7tM9LvrBCpl3gZIppcC2uJ6lH/0JsipuAazyWs1H3clsDDCZ/KKOENj2RAMJCjKgjaOC15eC9Q0xuZHdjHCZ/IIwPKPYCAhURe0UV/w8lygclcCJ0b4TBYBWP4RDCQgroI2ygtengvUMt6V5LU5J0l5nSAorwjA8o1gIAFxFrRRXfDyXKCW7a4kr805KD4CsPwiGEhAHgraegrULNylluWuJM/NOUnJwvFYVGzb4iIYSEBe7lxrKVCzdJdahruSPDfnJCFLx2OZti1BQv4RDCQkL3euYQrUpO9SueDko5YpLdSapLNtncM6E4DlE8FAgop255rkXSp3fPmqZUoDtSbJb9uFCxcSgBUEwQAyf5ca9o6v6DUIeallShq1JvEJuw0JwPKH4YhLOuxuFMtIagraMMPLag2Cjks/ffp081v/LqIiTYkclaSOx6LyuyZ4bdugUxkzVHj2UTOQM1FUl0dZ5Z7EXWrQOz7ajEGtSW2CXBO8tm21Ziua+PKBYCBHoijs4igw486FCNpOTpsxipibE7cw1wS3besXgBGg5wfBQI5EUdjVs4w02+KD3PHRZgykc13xCsAI0PODYCBHoijsal1GFqr6qt3xkWkPhBdnEE2Anh8EAzkSRWFXyzJmz57tWtXX2NhoEoiyVNjSZoyyC1uDF2cQTYCeHx0qlUol7ZVAOFFU1wddhrNGwA0JQYha0buHxqWeGrw4tzn7M/sIBhKSxslQ72fq+7V7XhCTJ0/mJEckstAklUde5yvnJoKgmaCgF7coPtMr+cfrtVxwUC+yz2tHsh7qwaBDKV3cgg6+UctgHfV+ZpSJiSiGpAaNCTPAFNoiWQ/1oGYgw9F6rXf3Ud0heCX/aMuS/bGmpibaGAvAa5snWbNFgVY7kvVQD4KBmC+qtV7c6qkujfKC6pWdv2LFCpk/f775/7x58+TDDz+UsWPHRnLhoc04eV7bPOlqewq0+tCbBrUiGEjgolrLxa2eu/uoL6jO/v1aQFiBgGXRokXmp96Cu57Ch9qE6Ld5Gu3QRSzQkjw2GYERtSAYSOCiqtm8YS9u9d7dx3lB9Wu/rfeusdbCh9qE2vlt87Sq7ZMs0OIuqItwbBJoFx/BQEIX1bAzzEU1wFCSEwdFcddYS+FDBnp9/LZ50avt4y6oi3BsFiGYQXUEAxGK+i4qq9WlbgVEVHeNtRQ+dKmqT7VtntXjsF5JNEnl/dgsQjCDYAgGIhTHXVRW2/+sAmLmzJkmVyDKu8awhU/YIIwqz/DbPKvHYT2SaJLKe++IvAczCI5gIGJFvYtyo9/t8MMPj6VwDVP4vPnmm4GXS5WntyIW+Ek3STnPhbw3s+Q9mEFwBAMxKNtFNc3v6zd3gvPuhSpPxNkktWDBAtdAM883CHkPZhAcwQByy61w97t7ocqzeOqtlYqqSaqlpcU30MzzDUKegxkERzCA3F3QrdcvW7bM8zVudy9eF3Jdji4z8ovcffeJ3HqryE9/KrLuuu2f/+gjkXPPFdlnH5Hdd5fceeM+kdduFRn2U5EGl+/X8pHI3HNF+uwjsunumR0ZMUxB7XWn3NDQEHugmWauS56DGQTDrIVIVdgLepAplSdOnCgjRowI/X797MjugO66S2TffUVWrRLZay+RG29sGxBoIDBpksgdd4h06iRyyy0ie+whufH6XSIP7CtSWSWy2V4iY25sGxBoIDBrksjrd4h06CTyxVtENgv//aZNm9ZmgCv7yIhpztDnLJjjXh9yXRA3JirK8aQueRd2QqVqzQLWXZpXIKD0AqoX6DFjxrR7TpetF/Tp06eb33oBrisQaGn57G8t+DUAsAcC+rjS1+nrrb9zEwi0fPa3FvwaALQJBD79Pvo6fb31d8DzxRkI2I+PMBMaxXE+agFvHzvEqjGwi6ptPaqJxwA/NBNEjAg+uLBt+F6v14K9R48ege/m9TVBZsGrKbnQHgisWbP2Mf1tBQRTp4p89atr/7Y/r/R9Wa8haBMIfLre+tsKCEZNFXn4q58W/Lbntf5R3+eoIfCbE8EeCLwj78jL8rJ8LB9Lh9kdZPRWo11Xz9kU5FWzkKe2dXJdkASCgQiRrR5vtyWvxwcMGBB6+wbtGhXqgqs5As5AwGIFBFtuKbJ8ufvzSt+vTQdZzCHQHIF2gYC0DQhu2lJk1XL3562AYNwdJocgyJwI/5H/yKPyqLwgL5i/O0pHuW3ObSJzRJq6NcnA5QNliAyRDtKh3Z24V81CnOdjHG3rdO9DEmgmiBBzsYcTtmo1yqpYt2XVfcHVZEHNEXAW9BZ93C0QsD+v79flZJEmC2qOQLuC3rLGIxCwPa/v1+VUOV+0pucBeUCukWtkuSyXiTJRzpFz5JptrpGV566UqQdMle7du8sNcoPM32K+HH3M0TJ+/HjfybTsy8+TOJsgAAs1AxEigo+/ajXKqljnspz9xENfcLXXwLPPtm0CcPJ6XHXsuLaJQJeTRdpr4L1nHU0ATmv87z20iUCX4zgvKlKRVbJKGqXRPH7dy9eZYGB32V12k93Mnb/S0S4fvP9BOWTCIXLIdofIn5/+sxx383HS95m+8vvP/T5QgZ/H85HufYgbvQki5mwD1QLFfseC7LFnhqu6Lrj25EC/gt8rEHD2OsiaNsmBIb6fFQjYeh20rGmRn97wU7n2uWtNc8AaWWMK/W17byvPvv2snD7ydDly4yNlxowZvln6lzx+iZx2+2ny5PFPyg59djCPeWX3NzU1ySTdPz5d9Riu+jNsi/IgGIjh5Fm4cGGotmxOuIIlfIYNCPISCNQcELQPBJ5/+3nZb+p+8vzS52VYr2EyftPxskXPLWSdruvIhY9eaB7fqPNGcv6I8+Xtf73dbonNzc0mm9+szpoW6f/7/jJ+q/EyZb8pnvvWHgh47feiJABHcU0pyrZAMDQTRHhiOU+e1atXVz0ROeEKmPCpBbr2GvBKFnQGAt26rX19HgIBpQW69hrwTBa06yjSqdva138aCLyw9AUZfdVo6d2ltzx23GMysu/INu84/8Hz5avbfVXe/+R9+caj35CD5CAZJIM8q/obOjbIiTucKOfNOk8u+vJF0nWdrr5V6177XV9ThARgvx4aQQOEWs4NbmryjWCgysHsdmKFvcB49XsvQu+DPF8AYuuypTUD2n2wWiBgTyrU1+epZkC7D1YNBGxJhfr6MTfKmo7rSPPUZhMIPHTsQ9JjvR5tXr1y1Up5dfmrss+AfeTQ7Q6VQ/5xiNz4/I1yyppTZEPZ0DOXY7fP7SYfrf7IvLfrR13bTRYUZL8vWbIk9134vK4pK1asCNXFMuy5wU1N/hEMfMqr0Hc7sdwOeq+TR9s79Tm3EyPv/YdruQBkKXiIJeGzlpwB+zgEhcwZ+Gwcgrv7nCQL3l4gjxz7SLtAQH3S8on5vU7DOuaO/8r9rpS+F/SVNUPWSPOWzZ7HTefGzub3zIdmynNzn5On5CmTh9BhvQ7Se8PeMmKzEXLyjiebnAKv/du3b1+ZPXt2rhMOva4pYbtYhjk3inBTA7oW+h7MVtu/H2skML8LhtdoYXnufVDLqGgaPEQywl9Wu2zVmjzoDAiskQpT4jliX83Jg58FBL2eOl523nSY7NJvF9dXbdB5A+nUsZO8+O6L5u9unbvJkU1HytSFU2Xwdt6Fi/X6C+ZeIBfJRfK4PC49padsvnJzGbLhELn9hdtlx//bUXb44w7ywbofuO53rcFLqwtfVKMkhrl2+PW4CHNu0KW6GEpfM6An35w5c+pahh70mszknMDE+RrniZTn6UHD1mpk9e4h0i5bOumQDhjkR3ME/Lod6vt1Ob/9rWSutkcnHdK5BqreX3h3O9xB3pKL+wySDh06uL+7Q0dpHtQsVz19lZy969nmdZo/8Mcn/yjPvf2cNG3S5Pq+y5+6XNbtuK68vOZl2Vv2liZpks6ytrZgm5ZtpP8H/WWhLJR73rpHdrp8J3nouIdk8uDJ7fZ7Gl34oqxid7umaOLkvHnzQgcOQbdFnm9q8JlSBwPVJr3R3gCaBFhtPHzroNeTR//v1hXK68TIa//hsBeALDeJRDZqnM4+ePHF7iMQ2pMFvXIJ9Hmd/U6Xk4KqAZvOPvj8xR4jENqSBT1yCSrSUVZV1sjb3Xf2XY9TdjpFxl09Tu5afJfsuc2e0nv93ubx9z56z/X1C95aIPf99z7p0thFjl5ztGwsG7d5XscmaJAGk4S4hWwhV6++Wva8Zk957vTnXPe79Zh1zMZ5fMYRJLtdU7p27VrTTUeQcyPPNzX4TGmDgWqT3lgHs/6EGZhGqxr1tWFOjDxODxr2AhAkeMhSPkFNdAhhnVtAhxRW9gLf6j7oNjeBPRDQ96c0FHHVgE2nIda5BcyQxOIo8D/tPug6N8Ha5zt0aJD9X2+QCVv3ky/7rMfYLcbK6M+NliOnHykPHvOgLP9Ygwtp7SVg97/3/ydf/uvapV3xlSuk1xu92hyTGtDbm/vWk/Xkq/JV+cPKP8g1c6+R03c+PdVkuLiCZOc1Je6bDmv59m7VyJfSjjOg7XPadu2khfnw4cN9T5YghVbuC7aANOFKs7A1+WrjjTf2/c5+AzIVKhvZOVmRcxwBZ26BPRBIcZKiwNPwtpusyDGOQLvcgo4iHRpMIDH69p/Iuo3ryj1H3uO7Lm998JaM/fNYefODN2XnvjvLrJdmyetnvd4aEGii4bQF0+Sce88xAcFG624kr5zxikk6dA4i5fadntzqSVm0YpE8e8qzbZoskp4aOe2pmKMUtOcVsqm0wYDfSag4gOtrZvEqzN2CpCJdENsFBDrXwF57te8lYAUEmiPQqVPqgUDoETRbA4JVIpvt1WZAIaM1ILhDpEOn1tkK/zrvr3LEjUfIglMXyKBebccOcFq2cpkZavjG5240vQsOGnKQ9OrSy9QU3LrwVhMo7L7V7vLUa0/J13f+uvxk3E8Cf6fVW642NQrO9fC6SbAPchS1Ioxa6nUO2+U6wC+B0jYTeFVzO5sBOIBra2bxavcM0+87C/kENdOCXQt6nXRI5xpwdhfUvzVA0GRBzRHIyCyFgauTtSZAZx/USYd0rgF7IKD0bw0QNOlQcw20iUFEDhxyoJx515ly6m2nyu2H324KeS/a9fDzPT9v/v+1pq/JM289I3PemGNqBw4ecrCcvNPJMrDnQGk8r1E+t+HnQn0nzTNQSz9cmnoyXBp5Q1EPxRzblOBITGmDAbeTUDmjWw7g2k/+oIV5YbORtYD3K+Q1IEip14Aft4DNtZDQAv7TQt6VBgQjfttuPIDrDrxO9vjLHmY44r9M+ov07NJ+P3+8+mP5wf0/kF898iv57R6/lW994VuuH6EVmw0dGlrHJwj6nT5u+dj8dgYjaSXDVcsbirLZMY6hmGOZEhyJKnUw4MwcXrZsmetrOIBrO/lbWlpMtWu1uw+ykcvVFjx2y7Fy62G3ygHXHyD9Luxnug4ett1hpteADkF86wu3yhVzrjB37RfueaF8c5dvei5L2/u1mv/Blx80vRCC0hyExo6NslX3rTLfwyfKfJq4hmJ2O4cLGeAXWGlzBoJ2L8x923VK265Pnz7y2muvhbr7qPXupyzJmnFavWa1PPvWs/LOyndkvU7ryYAeA6T7et1jbQvWJMEr51wplz55qbz03kutj2/YeUM5Zvtj5KQdT5KBvQZWXc5Fj14kZ999trx8xsuyaddNq75eL3mDLxkswzYdZmopsizqfBq/xGm30RfD5krYz0W3nld5y4Uok1LXDFRr91bcoYZrZtH/a42Ac6yFIHcftXSxLFQvhBRoJv4Vs68wg/a8svyV1sc7N3SWQ7Y7RCZsVH1b1tqUpjUB3xn9HTlr17Nk8TuL5d2P3pX1O60v/bv3NwFJUEdtf5T8v/v+n2lWuHzfyz0HNLL8+ek/m1kR9bVZF3U+TdxDMdvPYWe3bK6j2VbqYMDrRBszZoz06NGDAzgAZwGu/9e7jyQmgsnqqIZ58cCLD5hJg7S9/bChh5kkvc022Ew+XPWhGfBH79i1L/4oGSVfki9JR5/Ry+tpStPugFaiYC20W+FFe10kx8843tQq/HLCL81Ihm6m/nuqnHjLiXLs9sfKmC3GSNZ5FcZeTXDVeDXJ1TI+StDP41zMh1IHA14nmg6YwQFcO71QuenSpUuk7Yhec0eQ41Hdv175l+lap4P7TD1garskvu033V7O/MKZctFjF8lZd50lFanIHrJHZtuCjxtxnHzwyQdyxp1nyC0Lb5FTdjzFBDjaI0FnM7zlhVvMkMYaAGnQc9m+l1WtQcgCt8Jb7+LtNW9ha8O8ciKyliuBZJEzkHAf3zK0b/v11X7zzTcj2d5++QrkeFTPD9jm99tIv279zOA/OgiQn989+jtTyE4ZPUX2GLhHptuCH3nlEbO+OjaBfk+tIVhTWdM6zfGpO50qB297cC4CAbfrhlsTnJo4caI0NDQU+rqCeJU+GEiygC5L+7ZX0pNesN577z1Zvny5dOvWreYaGL+ktiwVTFl103M3SfN1zfLk8U+aKX1rSbjLelD72orXZOaLM+W9j98zeQjDNxsu2228nRQ10LYbOnSo7L///u0ez/o+Q7pK3UyQZLtWmdq33ao2tXeB845GJ4Gq5bv75XqMGzeuhjUul8ueukxG9h0ZKBBQehd98o4ny1l3n2USDjfpuknm24L7bNBHDh16qBRNkOaY+fPnm9/2gKAsNyKonXdGECKdh7xsc37rhUar67VpQGsE7N0MLXpxqmX+dr9cD1Q35/U5svc2e4d6zz6f38dUu+sogEg/0A4SEFjnlteNyP3331/T+YdiomagDmGi7cKOsufDunv06l3gluwXpCqTQYrq88GqD1xnAPRjvV6T9Moma9Xr9kQ/rxwC+7nldcMxa9Ys80MtARTBQELV/mUuwPwCHvtzYYIrMp+lrq54OslPGNo8YL23TLJavW5vpnnxxRdbmwbczq1qNxxFba5EODQT1KiWan971bn+Lkuim1fVpj0Y8gqu/Kox9b06OhoXsXAm9J8gU5+ZKi1r3LuAuvnb/L+ZQCBonkER1HJMpkFzAzRp0OvcCtK0UNTmSgRHzUCNaq32z3riVVysO3lrbABnT4KoRlrTzHcdNGfVmlXSrXM3z8FnykzH8L/q6atM3/v9Bu1X9fUrV62UKXOmmCGCu3RyHyuiiPI0m6YGBCNHjvSsKbOff9o0UKbmSgRDMFCjMlf718ovEKo3p+LV5a/Kn576kym0tFuZ6tSxk0waPMkMQKOjzeWtb3lcduyz49o+97edarrc+U3/q7UHx804zkwgFGYioCIIckxmKZ+g2o2G9bz24uG6BSfGGaiT82KQpYtDGQaA0sP3Fw/9Qr5///fNePZHDD3CjKqnU9P+993/molwdBx6DQb+efA/pVeXXgl8k+x7fcXrsuuVu5oeAlO+MkXG9x/frhblP+/8R86860y5+fmbzSiFB217UE2flddzwm1gK/sxmdV8giLvE8SHYCDCkyfPF4e8XqTOvfdc+dlDP5NzRp8j3x39XdM0YKeH9x2L7pCjph8lG6+/sTx07EOlS4LzojUoOo3wo68+amYpPKLpCDPrnzYL3PWfu+T2hbebbXV189UyceDEmj4jr+dEtdkCo55NsCjiCjIIXuJHM0FEF7QyDSoUpzA5FVpYaSDw6wm/NjPfudGmgS8P+LLMOmaWjLpylJx0y0ky9cCpEa91PunAPI8c+4g8/MrD8scn/igXPnqhmTlwvcb1ZOgmQ02Ngc5cWGueQJ7PiWr5AnnKJ0hKXIFfXgPKvCEYqBKFOsfS97qgcXFI3u8e+50ZSU8n1KlmUK9Bcv648+W020+T3yz/jRmXH2uDJW1W0R+l4/hHlXSZ53OiWr5AGccNSSPwy3NAmTekWjtMmzbNVP/p+N/6229ADzsuDslauHShmWZXJ54Jmhio1eB6l6uJhmURdIRMS5S9L/J8Trh1x6vWXa/MI2DGNcJq2UZuTRM1A45AwG3wjiAXNHoXJOvBlx80vw8aEjypbYPOG8jeA/Y209iWQdrVq3k/J6oNbGU9f+edd5pgS7vt6U8Zq7HjCvzyHFDmDcHAp/RkDhoIeF3QGBUvOcs/Xm7u8rUHQRg91+spz7/9vBRdVqpX835OVMthefzxx9vVupSxGjuuwC/vAWWeEAyErHbaeuutfbu7lXVQoaTptLSa9b6qZZV0augUKogIOy5/HmWpvb6o54TfDUQe8iLyEvjlPaDMC3IGQlY7LV68OHPDkZaRJg5WpCIzXnDP6XDz0eqPTDfDnfvuLEVH9Wq6NxC6ncPmaxRBXEOEM/R4/AgGQk4NqkheSd+wTYfJrpvvarrEBXXDMzfI0pVL5aQdT5Kiq5YAh/p5BVZNTU2yYMGCNonImr+BtryCpTIGUVnAoEMOViLQ8uXLzd9PP/10u9eUfWCRrJj676ly6D8PlWsnXWt6ClQbYGeXK3aRIb2HyB1H3CFlwWAtySZpaiCw0047MSBRjcmtaSe9lhk5A1XaN7t06ULySkYdsu0hpnvh0dOPlhUfr5ATdjhBGjo2tHvd/P/Nl/2v3980K+hAOmVS1Pb6rHBrz9a7WjdlzCMIk9yq2y8LSa9lRTBQBckr2aXjC/xp4p/MiHmn3HaK/OLhX8iJO5woozYf1To3gU5cdN9/7zODDs06epb07dY37dVGwQMu8jVqa2ZdsmSJ5+u57saPYCAA7q6yq7Fjo1yyzyVyzPBj5NInLpXzZp1nEgUtmlfwl0l/kQOHHCidGzunuq4oB7rD+fMKivr27SuzZ88O/HpEi5wBFIpOtbtk+RL5pOUT6b1+bzPxDpAG8jXCz1Bay8yliAbBAAAgM8ESQVQ6CAYAACg5xhkAAKDkSCAEANSFqv38IxgAANSMgYKKgWYCAECkAwgxlHD+EAwAAELTAn/OnDmuzzF/S/7QTAAAqKtpwImBgvKHmgEAQF1NA3aMtphP1AwAAALzagIYMWKEDB8+nEAgp6gZAAAE5tUEQCCQbwQDAIDQEzHZ0TSQfwxHDADI7EBDDGiUDHIGgBziAll8te7jIh0bDGiUHIIBIGe4QCYnrYK11n2c1LGRxOd4DWg0ePDg3Ac5WUTOAJAjjPiWHC3wpkyZItOnTze/9e8s7+Okjo2kPser1wIDGsWDYADIES6QxQ+6at3HSR0bSX2OV68FBjSKB8EAkCNcIIsfdNW6j5M6NpL6HHotJIucASBnbdd6gbTftXKBLFbQZRWCYfdxre9Lav1qoXkImiNQlITILKNrIZBxbslaXCCT3+5a4I0fPz6xz896b4Jqn1OkXg1lQDAAZJheUDV5zWny5MlcYBNAgZat3gbsj/jQTADktO2ai2H8dBuznbPRJZAutfEigRDIMBIGkTdxJF/SpTZ+BANAhpFRjVppQTl37tzEC8yoA1hd/zlz5rg+R5fa6NBMAGQcGdXIU5V6lL0NnN/DiRqy6JBACAAFkpWk03qT/by+R1q9O4qOmgEAKJCsJJ3Wm3zp9T1GjBghw4cPp4YsYgQDAFCArmvWure0tLg+7/V4Vnk1ARAIxINmAiBn8lxgZVmeu645171Pnz7y2muvtXtdnr5TFgZ+KhOCASBH8lxgZVlW2tmjXPfRo0fLQw89lMvvZEfwmwy6FgI5QV/r+OR5Nkivdfzwww9DvT6r3SI1ABg2bBiBQMzIGQByIiuJYUWU58GdvNaxb9++Mnv27MCvzwpqv9JBzQCQE3kusIo8uFNag/tUW3fNug/7ndL+LtR+pYeaASAnkpw6toxqGdwpK3exQdfdL0UsC9/Fq/bLGoGQYz0+JBACOUNCVTZkPekwzPpl5btUG2iIJoP40EwA5AwJVdmQ9aTDMOuXle+ix/TQoUM9n6fJID4EAwBQwByOMOuXle+iTRXz58/3fU1Wgq2iIRgAgALOKBlm/bLwXdySB7McbBUNOQMAUOAcjjDrl9Z3saYpdusKaec3AmHW90PWEQwAAFJTbZpiy8SJE013ySDLINEwPJoJAACpCNo0oBoaGgIvg0TD8BhnAMgYqjtRFmGSAZ25AtZ5smzZMs9lc/4ERzAAZAjVnShTMOuVDKjdC+29CpzJjEGaFkg0DIdgAMjIBXThwoWu1Z06shx3OChiMOs1qqYmCY4cOdI1qAjStJClXh15QTAApKzaXQ7VncgDr7b7asGs11DK+tvtfV5NC2PGjJEePXrQvFYjggEgRUHucqjuRNFn1fQq+MOcDwMGDCAIqAO9CYAMJ1BR3Ym8SGoUwywMkFRE1AwAKfK6UOqFbc899+QCh9xIclbNWmaYhD8GHQJSNm3aNNfx2L1mjKPrIbIsL8dnXtYzKdQMACnr3r174LZWuh4i66z2fy1s586dm8nClvOoPYIBIKM9CdwGWaHrIfIgy4Ut55E7EgiBDPYkcLa1WhO5uGFKV2RJ1ocH9uv1UGbUDAAp8esvPW7cuMDjEESdrU1bKtLqYlikXg95QzAApMSvv3TQcQjsNQhRFOJZrt5FPtRb2MYdjCbZ6yFPCAaAlLhdlJqamtpclPyqLu1TukZRiNOWirQL26SCUT2mGxvXFn8MVrQWwQCQIr3QrVixorVr4bx586Rr166tF8CWlpaqU7pGVYhnvXoX+VHLOABBj+N6ag70vTNnzpRFixa1PrZ69WqOb4IBIF16cXKOMWBdABcsWBAoVyCqQpy2VEQpzBDDQY/jemoOvHJvqP1ai94EQIq8LoBuMxja2atdoyrEGeYVaap2HNfTS6Fa7s3SkvckUNQMABm8AC5fvtz18YEDB8ro0aPbFNBRJkQxzCuS4FbVX+04rqcGrFph35PaL4IBIE1eF0ArH8Bpk002cb3wRVmIh63eBcLwq+r3O47rqQHzew21X2sxNwGQwTsl/XvKlCmB5ysA8qDe49oZSGhBPn78+ECf7Xyv9iLQMT2s821pyWvDCAaAjKrnwgdkkc5VMH369HaPNzc3y7BhwwIto97eBM73MrbGWjQTABkVtuqfuxtkXRTJrvU0Yznfy9ganyEYADIs6IUvC3c3BCPI0uh/ejxqrxy/gYUYW+MzBANAzmXh7sYvGCFIKI4o9mUSPVacx+OsWbNcA2TG1vgMwQCQc2nf3fgFI86Bk8raHlsEUdY+xdljxWtMAbcAmXkKPkMwAORc2nc3YQZOKmt7bN5lofYpKL8xBfSYdK4vY2usxQiEQM6lPXJg2KCD0d6KVfuUNX7HozYXaA2HU79+/UxvhrIGAoqaAaAA0ry78apq1aQtvfg6lbE9Nu+Sqn2KIifB7XjMQ41G2hhnAEAkgvThZqyE/Ip7X0bdI2batGntJgGz6GBD48aNq3nZRUTNAIBIuCWF0R5bHHHuy6hzEtxmA4U/ggEAsWKug+ik3U0zrn0ZdY+YarkM2oSFtggGACAHhXkWBpbKS04CExOFRzAAAAmopzDPU9e+WkTd399tefaJidAewQAAxKzewryeavQomhZqWUbY90Q9Fwf5KuEQDABAzOptE6+1Gj2KpoVallHr50Y9Fwf5KsEx6BAAZLxNvJaBpbxqI/TxoLyWMXv2bDMdsduyovjcWtYpquWXFTUDADIlTPVy2tn1SbaJh632jiJD32sZM2bM8JyUas6cOXV/bi3rVMaZBqNEMAAgM8JUL+ctu76eNnFl/V+HzU0qQz/Ia70mparnc2tZJ0a2rA/BAIDcJdnlNbu+1jZxuzDt7/XWRlQb2tdvUqq4uvMx02A8CAYAZEKY6t8iVxV7TcFbS9ATRUa9fRktLS1tmgiqGTFihAwfPjzyfUJPgegRDADIhDDVv1ooufF6PE+CzAQYJuiJIqPevgz97KCTUsURCLitE+pHMAAgE9yqf5uamloLR/uFv6GhwXUZXo/nSZC27zTbx73uyqm6zzdmLQSQCq+eANbjixcvbjPZzNChQ2X//fdvfc2UKVPaLXPy5MmFKID8cgayNPOjcx/mpXcH2iMYAJC4aj0BvAp7e0BQ9OmRvXoTxDUCYFh5680BfzQTAEhUkJ4AXu3mWlMwcuRI87qiJ5E528TDfL+4C+og+5BagnwhGACQKK+C3hqsRgsOvzZxe/IcSWTtJdHtslpvDmoN8ofhiAEkyqug1yFutWlACxItULRJwI3mEqC2gjqJnh8MF5xPBAMAEuU2zr5bwaG5AVtvvbVrUwEFS7oj9PnNlZBEMILo0UwAIHFWe782DWiNgFd1s9YOuNUEFGFwobgkNUKfV84GwwXnE8EAgFRYhYdbMGAVHBQstUkqudItZyNoMEKCYbbQtRBAqqp1ESx6F8K8CVqI+72OBMPsIRgAkPkCpsh3kXn6blEU4kUfMCqvaCYAkLpqXQSL2oUwT3fIUXVZLPIkU3lGbwIASEHeuuBF1UuAPJBsIhgAgBTkrQteVIW4X7dEpIdmAgBIQd7ukMN0WayWB1H0oaTziARCAEhJHntKVCvo85QHgc8QDABAivLUm6AaegrkF80EAJCiIvWUoKdAfpFACAAoZR4EPkMwAACIBD0F8oucAQBAYnkQRcqRKBKCAQBATcIW7PQ0yC4SCAEAoYUt2KMazhjxIGcAABCKV8HuNh11XkdcLBuCAQBAKF4F+IwZM0yNgRt6GmQbwQAAIBS/AtxrsiV6GmQbCYQAgLpzBuyam5tl2LBhrs/RmyCbSCAEAISmyYJaoGvTQJiagyKNuFgkNBMAAGoyYsQIqv4LgmYCAEBdqPrPP4IBAEAkBT5BQX6RMwAAqHuAIUYXzDdyBgAAoQcYsncfDPIaZBvBAACgrpEDGV0w/wgGAACegowcyOiC+UcwAADwFGTkQEYXzD96EwAAqqI3QbERDAAAUHI0EwAAUHIEAwAAlBzBAAAAJUcwAABAyREMAABQcgQDAACUHMEAAAAlRzAAAEDJEQwAAFByjWmvAAAgexhauFwIBgAAbdx9993yyCOPtP6tkxBNmDDB9z0ED/lGMAAAaC3MW1pa2gQCSv8ePHiwZyFfS/CAbCEYAICScd7FOwtzN/p6t2BAlxU2eED2EAwAQIk4C/6hQ4fK/Pnzq75PAwe3QGDOnDmewYP1m6aD7CMYAICScLuLDxIIjBo1ql1hXq02YfHixTJ9+vTWv2k6yDaCAQAoCetuPYiJEydKQ0OD6129W1Bh19TUJPPmzWvzGE0H2UYwAAAl4VbV71UTMGLEiNBBhb5n+PDh5nlnMGC9j2Agmxh0CABKQgtira73M2bMGBk/fnxNQYUGAvoZXs8HDUaQPIIBACgRbbefPHmyKfTdDBgwoKagwp5XUO15ZE+HSqVSSXslAADJcyYBalt///79A2f/VxtoiIGI8oNgAABKwKtgth7X7H97zwKy/8uFBEIAKDi/EQKtwMDeDVCR/V8u5AwAQIF5jRCoj1frHRCmKyLyjWAAAAosSEFP9j8IBgCgwIIU9AsWLGj3PNn/5UIwAAAFVq2bn9dogoMGDUpsHZE+EggBoOA0WVCTAd16E/g1I1AzUB4EAwBQAlqwuxXu5AtA0UwAACXGaIFQDDoEAGC0wJIjGAAAoORoJgAAoOQIBgAAKDmCAQAASo5gAACAkiMYAACg5AgGAAAoOYIBAABKjmAAAICSIxgAAKDkCAYAACg5ggEAAEqOYAAAgJIjGAAAoOQIBgAAKDmCAQAASo5gAACAkiMYAACg5AgGAAAoOYIBAABKjmAAAICSIxgAAKDkCAYAAJBy+/+zsqvmMqN7PAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(\n",
    "    projected_dataset_embeddings[:, 0],\n",
    "    projected_dataset_embeddings[:, 1],\n",
    "    s=10,\n",
    "    color=\"gray\",\n",
    ")\n",
    "plt.scatter(\n",
    "    projected_retrieved_embeddings[:, 0],\n",
    "    projected_retrieved_embeddings[:, 1],\n",
    "    s=100,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"g\",\n",
    ")\n",
    "plt.scatter(\n",
    "    projected_original_query_embedding[:, 0],\n",
    "    projected_original_query_embedding[:, 1],\n",
    "    s=150,\n",
    "    marker=\"X\",\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.scatter(\n",
    "    projected_augmented_query_embedding[:, 0],\n",
    "    projected_augmented_query_embedding[:, 1],\n",
    "    s=150,\n",
    "    marker=\"X\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "\n",
    "plt.gca().set_aspect(\"equal\", \"datalim\")\n",
    "plt.title(f\"{query}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()  # display the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prp_class",
   "language": "python",
   "name": "prp_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
