{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I ran my file in colab. But due to some technical issues, I was unable to upload it via colab. So I have downloaded a copy in my vs code and i am uploading it from there. But all the settings are as per colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24PQnY1i0-rj"
   },
   "source": [
    "Referenced Sites:\n",
    "* https://docling-project.github.io/docling/examples/hybrid_chunking/#overview\n",
    "\n",
    "* https://www.youtube.com/watch?v=9lBTS5dM27c&list=WL&index=2&t=1s\n",
    "\n",
    "* Contextual Chunking-> https://www.anthropic.com/news/contextual-retrieval\n",
    "\n",
    "* LanceDB embeddings-> https://lancedb.github.io/lancedb/embeddings/default_embedding_functions/#text-embedding-functions\n",
    "\n",
    "I am doing text embeddings only. Not multi-modal embeddings.\n",
    "\n",
    "* Building with Google's gemini embeddings-> https://lancedb.github.io/lancedb/embeddings/available_embedding_models/text_embedding_functions/gemini_embedding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rRU40ieyLoG",
    "outputId": "c3f41e60-cee9-4542-8688-ced7e647747f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docling\n",
      "  Downloading docling-2.40.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (2.11.7)\n",
      "Collecting docling-core<3.0.0,>=2.39.0 (from docling-core[chunking]<3.0.0,>=2.39.0->docling)\n",
      "  Downloading docling_core-2.40.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting docling-parse<5.0.0,>=4.0.0 (from docling)\n",
      "  Downloading docling_parse-4.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting docling-ibm-models<4,>=3.6.0 (from docling)\n",
      "  Downloading docling_ibm_models-3.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pypdfium2<5.0.0,>=4.30.0 (from docling)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic-settings<3.0.0,>=2.3.0 (from docling)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.11/dist-packages (from docling) (0.33.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from docling) (2.32.3)\n",
      "Collecting easyocr<2.0,>=1.7 (from docling)\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2025.6.15)\n",
      "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
      "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typer<0.17.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from docling) (0.16.0)\n",
      "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from docling) (4.13.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2.2.2)\n",
      "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
      "  Downloading marko-2.1.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from docling) (3.1.5)\n",
      "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (5.4.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (11.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from docling) (4.67.1)\n",
      "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.6.0)\n",
      "Collecting pylatexenc<3.0,>=2.10 (from docling)\n",
      "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.15.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.14.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (4.24.0)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling)\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (0.9.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (6.0.2)\n",
      "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling)\n",
      "  Downloading latex2mathml-3.78.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.39.0->docling)\n",
      "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.39.0->docling) (4.53.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4,>=3.6.0->docling) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4,>=3.6.0->docling) (0.21.0+cu124)\n",
      "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4,>=3.6.0->docling) (4.11.0.86)\n",
      "Requirement already satisfied: safetensors<1,>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4,>=3.6.0->docling) (0.5.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4,>=3.6.0->docling) (2.0.2)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.25.2)\n",
      "Collecting python-bidi (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (2.1.1)\n",
      "Collecting pyclipper (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (24.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (1.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.3.0->docling)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
      "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (13.9.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4,>=3.6.0->docling) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (0.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (2.19.2)\n",
      "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.39.0->docling)\n",
      "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (0.21.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.6.11)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling) (3.0.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.11/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (0.70.15)\n",
      "Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.39.0->docling) (0.3.7)\n",
      "Downloading docling-2.40.0-py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.0/186.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling_core-2.40.0-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling_ibm_models-3.7.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling_parse-4.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading marko-2.1.4-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading latex2mathml-3.78.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
      "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=6f65f4d99684a8a940cd61dd137631296a665b943e3022e92c33a6d938452037\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/7a/33/9fdd892f784ed4afda62b685ae3703adf4c91aa0f524c28f03\n",
      "Successfully built pylatexenc\n",
      "Installing collected packages: python-bidi, pylatexenc, pyclipper, filetype, XlsxWriter, rtree, python-dotenv, python-docx, pypdfium2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, mpire, marko, latex2mathml, jsonref, jsonlines, python-pptx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, semchunk, pydantic-settings, nvidia-cusolver-cu12, docling-core, docling-parse, easyocr, docling-ibm-models, docling\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed XlsxWriter-3.2.5 docling-2.40.0 docling-core-2.40.0 docling-ibm-models-3.7.0 docling-parse-4.1.0 easyocr-1.7.2 filetype-1.2.0 jsonlines-3.1.0 jsonref-1.1.0 latex2mathml-3.78.0 marko-2.1.4 mpire-2.10.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 pydantic-settings-2.10.1 pylatexenc-2.10 pypdfium2-4.30.1 python-bidi-0.6.6 python-docx-1.2.0 python-dotenv-1.1.1 python-pptx-1.0.2 rtree-1.4.0 semchunk-2.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NMag9RGuySXL"
   },
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "converter= DocumentConverter()\n",
    "\n",
    "result= converter.convert('combined_markdown.md')\n",
    "result= result.document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3R9hQOg29Nbh"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILEfGCYLyDMG",
    "outputId": "5503b62c-320e-4761-f881-37cd2c71e4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0GSBLJMEy1X0"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "token= userdata.get('HF_TOKEN_ORIGINAL_AGENTCOURSE')\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fC371pyurN2"
   },
   "source": [
    "Setting up the configurations of bitsAndBytes config.\n",
    "\n",
    "Note-> the latest version ,when i made this notebook, of bitsandbytes==0.46 is supported by only cuda==12.3. while the latest version of cuda is 12.4.\n",
    "So i made the following changes. make these changes only after a proper research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kQ1G9yluf1B"
   },
   "outputs": [],
   "source": [
    "# 1. Clean broken bitsandbytes installs\n",
    "!pip uninstall -y bitsandbytes\n",
    "!rm -rf /usr/local/lib/python*/dist-packages/bitsandbytes*\n",
    "\n",
    "# 2. Set the manual override for CUDA 12.3\n",
    "import os\n",
    "os.environ[\"BNB_CUDA_VERSION\"] = \"123\"\n",
    "\n",
    "# 3. Reinstall the latest bitsandbytes (supports 12.3)\n",
    "!pip install bitsandbytes\n",
    "!pip install -U transformers accelerate\n",
    "\n",
    "# 4. Verify CUDA backend\n",
    "!python -m bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "d636ae1508274bc5804888c1206b3e29",
      "0d829ccb93694075b4f0b92457f9604a",
      "8be14fba878243f0bf31eb6cd2ffae2a",
      "a5fc900c513f45cb9004d4f1b54a9f8d",
      "aa8e54b464084f498c077f8679faa11a",
      "65ba757e5312419a8e2af9dc697c165b",
      "e345cb72393e4a2bbb021f0df40a9c2a",
      "0a0d6e53ac114d708f88723942de1cdd",
      "64f1e24e51824670ab4f920ae36e2b99",
      "88d66c5e4292407ea49bbcf288c1a8aa",
      "115c81cb7a044a88ab9393eb0187b884",
      "aa51265536d04629a76a80d707cda1af",
      "3ee67c91042945c7bc1a44552cc6a474",
      "4ee7b71cc8f34ddbbde54b23c661def0",
      "2961d677019a46dabfe501f68d1ae4a5",
      "abc9a9adf21b44e5b000aa10ae98606d",
      "69a78116f1e44b29b3395d345692f881",
      "adbec221717348869191c8d19ff436dc",
      "77e4427c3eeb4915b1e198c7da571401",
      "05985096fd724ab6af7d9a84b377d102",
      "d7289f83d5ac4a88a1348f2edc99120f",
      "a769dfd3359049b69b683977faf23b8d",
      "aaef0429b8d34021b9016b5ebf82fb0e",
      "c9af8f41161840dc89de0713b5b7dec6",
      "a8ec18c57dfd4588900c6f7cf5218da3",
      "64e0b44667ec42beb3671c307e29a1bc",
      "c7823cca8f9b4e3cb7693d6e2f00c91d",
      "8c5b253e2518486b8cd702c60108ebde",
      "dec13c6c29cc46c68d2f8e2f445ad5ac",
      "00585da592104561847790a09b5240f3",
      "29b47da5cbe44f0cb2299c92f715a371",
      "17715f375c8a4231add56e0ca9f93ea0",
      "b37232b11921450fafce136ea8c9770d"
     ]
    },
    "id": "g-QSVDt7yKsA",
    "outputId": "f1dfc840-d90b-4b03-a8c8-9aa0ffa01b28"
   },
   "outputs": [],
   "source": [
    "# loading the model for tokenizing\n",
    "\n",
    "from transformers import BitsAndBytesConfig, Gemma3ForCausalLM\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "model = Gemma3ForCausalLM.from_pretrained(\n",
    "    \"google/gemma-3-1b-it\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuxGftZ1yrJz",
    "outputId": "0a7f82d6-f5cb-441c-ffbf-bacf1c4e5fd1"
   },
   "outputs": [],
   "source": [
    "# let us work on the chunking using docling\n",
    "!pip install -qU pip docling transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVPaew7k4I51"
   },
   "outputs": [],
   "source": [
    "# if you want to use the hugging face tokenizers\n",
    "!pip install 'docling-core[chunking]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CzPLjVh2gMa"
   },
   "source": [
    "In RAG it is important to make sure that the chunker and the embedding model are using the same tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsPxmUrz6tFY"
   },
   "source": [
    "okay so currently i do not see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "b40d3f81a5014043a10cfbde89d66ecd",
      "a381c0c1836f4c3fa1d971f5ba54b57b",
      "6cc0a7535c654f14bd96bd4ed1832a55",
      "5918422dec27466cb6a7a56e64122c86",
      "a08d31975a43420a9abcb0fea14d353f",
      "58f0048670444e62a8805e5820285827",
      "91390b11123948b685ae5f22a03eefda",
      "6d728a8549e04aa8aff63b9a4749d544",
      "aefd7b0dec8f4f1f8124bdab61ed98f4",
      "c68d58904d984dffbe9a4969b9581b21",
      "0ddef78f25bc413f91b3f4551571d9b2",
      "3c6fc2a4068e4ef29503e32925150c42",
      "425e6ad1a5fd45c19311cfc80441996b",
      "732b31cc0e994d729d1aceac8306a0da",
      "8ea35062062344edad18247a8a048695",
      "a2415ebb6c924849976f2f3d22eb1cc3",
      "8b27fb8dd60f41f9a4079869c71c982b",
      "1b23c3ab63044c278b73be7700bcfdd6",
      "78ee812ef7a4400d8e49a8ff4846975e",
      "81d174ed955244379ed701fa6b194cea",
      "d0c8be2a7c4141349c2feea8abb6213e",
      "42fa9311eeef419dbf4fa7f97929b9a9",
      "90146c402bfb40c19c500856557491ff",
      "459120afb99e4bd68a2e110656c2b9cd",
      "f68177b0629d45c28da066d8d23f2652",
      "d06b129919f843f791cf0cbbf33ea5c3",
      "04246ad56c8c4045bef9b34f24ce37b2",
      "17e554cf731f4535ba59d565e232d9bd",
      "5c786287ae154a46a5dd6a469f010fb3",
      "b6169d41005845079c48142b35ac5a1d",
      "2df48b4cd8364f2dad5c6db5874d45b5",
      "6886898dd166408ab144af66f69f987a",
      "a8c85c8930724f0295a5f9d56c9db11b",
      "4790685fbde24b96a07dcffd00317726",
      "51b9a4b5a96c489ca9f6ddae7def97ef",
      "451db337f5db429291dd645dd6a5396c",
      "be649ebdbe0f4fbe8549beb508389211",
      "8b766007dc174362a411b0c2e414ec4f",
      "c10296c9bfd542bfbcceb94096096e74",
      "f39ff2d08300427690662de76f4140e8",
      "9c4bd2b09301419daaf6c021eef87b3c",
      "5c339db377bb4a9795f51c61b9d158c1",
      "607659659db445ce9aae2415ec33ed29",
      "1357b1418260430689e317934ec81eb0",
      "4ab7b6ec6f014fc4bc6fa0acacc275c8",
      "5e29048ea1e9436eaafbc9b792eb5ea9",
      "8219e742118848e686f739f9dc5f36ed",
      "96cc8036170143bf8430416399e445be",
      "789af491ec4b47d3ac0a97fff5b06d34",
      "7cd18be612b1429d91fc34bc4ae75468",
      "69668daa4ddf40da957416a98f58f208",
      "4b2bb1bcfcf64c3a9558a2af1db11a36",
      "7b826af1c03f461cbbb87f7a172bb0bf",
      "51dcca9da77f4d538ae947d388c9679f",
      "20f9de157242461abcb7fd2349c142f4"
     ]
    },
    "id": "EsloMcg_zdGr",
    "outputId": "869ee77a-80e4-4599-a74e-b4a2eff1866b"
   },
   "outputs": [],
   "source": [
    "# lets build our tokenizer\n",
    "from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "model_id= \"google/gemma-3-1b-it\"\n",
    "\n",
    "max_tokens= 400\n",
    "\n",
    "tokenizer= HuggingFaceTokenizer(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_id),\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IkZ0EDGq4eRL"
   },
   "outputs": [],
   "source": [
    "# now we can build our chunker\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "chunker= HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    merge_peers= True # merges the undersized chunks that share the same headings or metadata\n",
    ")\n",
    "\n",
    "def build_and_get_chunks(doc):\n",
    "  chunk_iter= chunker.chunk(doc)\n",
    "  chunks= list(chunk_iter)\n",
    "\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8eY9P7Oy-uIt"
   },
   "outputs": [],
   "source": [
    "chunks= build_and_get_chunks(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17Ueq0nx9yRV"
   },
   "source": [
    "we want to embed the contextualized chunkings. so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "racuIXEE9R3s"
   },
   "outputs": [],
   "source": [
    "def get_contextualized_chunks(chunks):\n",
    "  contextualized_chunks= []\n",
    "  for chunk in chunks:\n",
    "    enriched_text= chunker.contextualize(chunk=chunk)\n",
    "    contextualized_chunks.append(enriched_text)\n",
    "  return contextualized_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c-X04UYk-tIZ"
   },
   "outputs": [],
   "source": [
    "contextualized_chunk_list= get_contextualized_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "c1kgs2oUNCvO",
    "outputId": "27246d3a-1717-45ad-8402-853dc050e15a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Dear\\tRon,\\tand\\tHarry\\tif\\tyou're\\tthere,\\nDraco\\tturned\\taway\\tand\\tsaw\\tthe\\tcabinet\\tright\\tin\\tfront\\tof\\thim.\\tHe\\twalked forward\\t…\\the\\tstretched\\tout\\this\\thand\\tfor\\tthe\\thandle\\t…\\n'Done,'\\tsaid\\tMr\\tMalfoy\\tat\\tthe\\tcounter.\\t'Come,\\tDraco!'\\nHarry\\twiped\\this\\tforehead\\ton\\this\\tsleeve\\tas\\tDraco\\tturned\\taway.\\n'Good\\tday\\tto\\tyou,\\tMr\\tBorgin,\\tI'll\\texpect\\tyou\\tat\\tthe\\tmanor\\ttomorrow\\tto pick\\tup\\tthe\\tgoods.'\\nThe\\tmoment\\tthe\\tdoor\\thad\\tclosed,\\tMr\\tBorgin\\tdropped\\this\\toily\\tmanner.\\n'Good\\tday\\tyourself, Mister Malfoy,\\tand\\tif\\tthe\\tstories\\tare\\ttrue,\\tyou\\thaven't sold\\tme\\thalf\\tof\\twhat's\\thidden\\tin\\tyour manor …'\\nMuttering\\tdarkly,\\tMr\\tBorgin\\tdisappeared\\tinto\\ta\\tback\\troom.\\tHarry\\twaited for\\ta\\tminute\\tin\\tcase\\the\\tcame\\tback,\\tthen,\\tquietly\\tas\\the\\tcould,\\tslipped\\tout\\tof\\tthe cabinet,\\tpast\\tthe\\tglass\\tcases\\tand\\tout\\tof\\tthe\\tshop\\tdoor.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualized_chunk_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2zx8WtoOp1ja"
   },
   "outputs": [],
   "source": [
    "! pip install -U -q 'google-genai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G7Ns4Eijb1rF"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client=genai.Client(api_key=userdata.get('GOOGLE_2_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYGIdSrGisHV"
   },
   "outputs": [],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dDZdrbWuomQ9"
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "\n",
    "# creating a cutsom embedding function, that plugs into chromadb\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "  def __init__(self):\n",
    "    # embedding function is an abstract base class in chromadb\n",
    "    pass\n",
    "    # required by chromadb\n",
    "\n",
    "\n",
    "# overwrites the __call__ func() of chromadb, to generate embeddings on demand\n",
    "  def __call__(self, input:Documents) -> Embeddings:\n",
    "    Embedding_Model_ID= \"models/text-embedding-004\"\n",
    "\n",
    "    # ensuring input is always a list, even if a single string.\n",
    "    if isinstance(input, str):\n",
    "      input= [input]\n",
    "\n",
    "    all_embeddings=[]\n",
    "    batch_size=100\n",
    "\n",
    "    for i in range(0, len(input), batch_size):\n",
    "      batch= input[i:i+batch_size]\n",
    "      try:\n",
    "        response= client.models.embed_content(\n",
    "            model=Embedding_Model_ID,\n",
    "            contents= batch,\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type='retrieval_document',\n",
    "\n",
    "            )\n",
    "        )\n",
    "        # return all teh embeddings\n",
    "        batch_embeddings= [emb.values for emb in response.embeddings]\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f\"Embedding error:{e}\")\n",
    "        return None\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "I4m_jTWhqWpF"
   },
   "outputs": [],
   "source": [
    "# fix chromadb for batch processing\n",
    "import chromadb\n",
    "def create_chroma_db(contextualized_chunk_list):\n",
    "  chroma_client= chromadb.PersistentClient(path=\"novel_collection_embeddings_3\")\n",
    "\n",
    "  collection= chroma_client.get_or_create_collection(\n",
    "      name='bing_novelrag_collection_3',\n",
    "      embedding_function=GeminiEmbeddingFunction()\n",
    "  )\n",
    "  print(f\"Adding {len(contextualized_chunk_list)} chunks to database...\")\n",
    "\n",
    "  # add documents in batches to avoid memory issues\n",
    "  batch_size=50\n",
    "\n",
    "  for i in range(0, len(contextualized_chunk_list), batch_size):\n",
    "    end_idx= min(i+batch_size, len(contextualized_chunk_list))\n",
    "    batch_docs= contextualized_chunk_list[i:end_idx]\n",
    "    batch_ids= [str(j) for j in range(i, end_idx)]\n",
    "\n",
    "\n",
    "    # triggers embedding via geminiembeddingfunction call\n",
    "    collection.add(\n",
    "        documents= batch_docs,\n",
    "        ids= batch_ids\n",
    "    )\n",
    "\n",
    "    print(f\"Added batch {i//batch_size + 1}/{(len(contextualized_chunk_list)+ batch_size - 1)//batch_size}\")\n",
    "\n",
    "\n",
    "  print(f\"Database created with {collection.count()} documents\")\n",
    "\n",
    "  return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tx3gdlb5rULX",
    "outputId": "89ca715c-7f55-4829-e86c-0b2eb9c3597d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 1346 chunks to database...\n",
      "Added batch 1/27\n",
      "Added batch 2/27\n",
      "Added batch 3/27\n",
      "Added batch 4/27\n",
      "Added batch 5/27\n",
      "Added batch 6/27\n",
      "Added batch 7/27\n",
      "Added batch 8/27\n",
      "Added batch 9/27\n",
      "Added batch 10/27\n",
      "Added batch 11/27\n",
      "Added batch 12/27\n",
      "Added batch 13/27\n",
      "Added batch 14/27\n",
      "Added batch 15/27\n",
      "Added batch 16/27\n",
      "Added batch 17/27\n",
      "Added batch 18/27\n",
      "Added batch 19/27\n",
      "Added batch 20/27\n",
      "Added batch 21/27\n",
      "Added batch 22/27\n",
      "Added batch 23/27\n",
      "Added batch 24/27\n",
      "Added batch 25/27\n",
      "Added batch 26/27\n",
      "Added batch 27/27\n",
      "Database created with 1346 documents\n"
     ]
    }
   ],
   "source": [
    "# Set up the DB\n",
    "collection_built = create_chroma_db(contextualized_chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOJJTDIAxRoq",
    "outputId": "2218ff81-dcda-46de-c12e-097ff27c4522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       " 'embeddings': array([[-0.03861213,  0.02344161, -0.00374704, ...,  0.00964072,\n",
       "          0.0244747 , -0.01426351],\n",
       "        [-0.02072495,  0.02093361, -0.00411656, ...,  0.05033953,\n",
       "         -0.00417255, -0.02308157],\n",
       "        [-0.0383333 ,  0.01372326, -0.02511429, ...,  0.06165662,\n",
       "          0.01992766,  0.00818526],\n",
       "        ...,\n",
       "        [-0.03405032,  0.00664998, -0.00151566, ...,  0.0002513 ,\n",
       "          0.04247424, -0.03012509],\n",
       "        [-0.05485309, -0.00544187,  0.01287586, ..., -0.02370497,\n",
       "          0.02652791, -0.02154174],\n",
       "        [-0.03307312, -0.00749543, -0.02514764, ...,  0.01036208,\n",
       "         -0.01646801, -0.03018571]]),\n",
       " 'documents': ['HARRY POTTER\\nand\\tthe\\tChamber\\tof\\tSecrets\\nJ.K.\\tROWLING\\nAll\\trights\\treserved;\\tno\\tpart\\tof\\tthis\\tpublication\\tmay\\tbe\\treproduced\\tor\\ttransmitted\\tby\\tany\\tmeans, electronic,\\tmechanical,\\tphotocopying\\tor\\totherwise,\\twithout\\tthe\\tprior\\tpermission\\tof\\tthe\\tpublisher\\nThis\\tdigital\\tedition\\tfirst\\tpublished\\tby\\tPottermore\\tLimited\\tin\\t2012\\nFirst\\tpublished\\tin\\tprint\\tin\\tGreat\\tBritain\\tin\\t1998\\tby\\tBloomsbury\\tPublishing\\tPlc\\nCopyright\\t©\\tJ.K.\\tRowling\\t1998\\nCover\\tillustrations\\tby\\tClaire\\tMelinsky\\tcopyright\\t©\\tJ.K.\\tRowling\\t2010\\nHarry\\tPotter\\tcharacters,\\tnames\\tand\\trelated\\tindicia\\tare\\ttrademarks\\tof\\tand\\t©\\tWarner\\tBros.\\tEnt.\\nThe\\tmoral\\tright\\tof\\tthe\\tauthor\\thas\\tbeen\\tasserted\\nA\\tCIP\\tcatalogue\\trecord\\tof\\tthis\\tbook\\tis\\tavailable\\tfrom\\tthe\\tBritish\\tLibrary\\nISBN\\t978-1-78110-008-0\\nwww.pottermore.com\\nby\\tJ.K.\\tRowling\\nThe\\tunique\\tonline\\texperience\\tbuilt\\taround\\tthe\\tHarry\\tPotter\\tbooks.\\tShare\\tand participate\\tin\\tthe\\tstories,\\tshowcase\\tyour\\town\\tPotter-related\\tcreativity\\tand discover\\teven\\tmore\\tabout\\tthe\\tworld\\tof\\tHarry\\tPotter\\tfrom\\tthe\\tauthor\\therself.\\nVisit\\tpottermore.com',\n",
       "  'HARRY POTTER\\nFor\\tSéan\\tP.F.\\tHarris, getaway\\tdriver\\tand\\tfoulweather\\tfriend',\n",
       "  \"CONTENTS\\nONE The\\tWorst\\tBirthday\\nTWO Dobby's\\tWarning\\nTHREE The\\tBurrow\\nFOUR At\\tFlourish\\tand\\tBlotts\\nFIVE The\\tWhomping\\tWillow\\nSIX Gilderoy\\tLockhart\\nSEVEN Mudbloods\\tand\\tMurmurs\\nEIGHT The\\tDeathday\\tParty\\nNINE The\\tWriting\\ton\\tthe\\tWall\\nTEN The\\tRogue\\tBludger\\nELEVEN The\\tDuelling\\tClub\\nTWELVE The\\tPolyjuice\\tPotion\\nTHIRTEEN The\\tVery\\tSecret\\tDiary\\nFOURTEEN Cornelius\\tFudge\\nFIFTEEN Aragog\\nSIXTEEN The\\tChamber\\tof\\tSecrets\\nSEVENTEEN The\\tHeir\\tof\\tSlytherin\\nEIGHTEEN Dobby's\\tReward\",\n",
       "  \"The\\tWorst\\tBirthday\\nNot\\tfor\\tthe\\tfirst\\ttime,\\tan\\targument\\thad\\tbroken\\tout\\tover\\tbreakfast\\tat\\tnumber four,\\tPrivet\\tDrive.\\tMr\\tVernon\\tDursley\\thad\\tbeen\\twoken\\tin\\tthe\\tearly\\thours\\tof the\\tmorning\\tby\\ta\\tloud,\\thooting\\tnoise\\tfrom\\this\\tnephew\\tHarry's\\troom.\\n'Third\\ttime\\tthis\\tweek!'\\the\\troared\\tacross\\tthe\\ttable.\\t'If\\tyou\\tcan't\\tcontrol\\tthat owl,\\tit'll\\thave\\tto\\tgo!'\\nHarry\\ttried,\\tyet\\tagain,\\tto\\texplain.\\n'She's bored, '\\the\\tsaid.\\t'She's\\tused\\tto\\tflying\\taround\\toutside.\\tIf\\tI\\tcould\\tjust let\\ther\\tout\\tat\\tnight\\t…'\\n'Do\\tI\\tlook\\tstupid?'\\tsnarled\\tUncle\\tVernon,\\ta\\tbit\\tof\\tfried\\tegg\\tdangling\\tfrom his\\tbushy\\tmoustache.\\t'I\\tknow\\twhat'll\\thappen\\tif\\tthat\\towl's\\tlet\\tout.'\\nHe\\texchanged\\tdark\\tlooks\\twith\\this\\twife,\\tPetunia.\\nHarry\\ttried\\tto\\targue\\tback\\tbut\\this\\twords\\twere\\tdrowned\\tby\\ta\\tlong,\\tloud\\tbelch from\\tthe\\tDursleys'\\tson,\\tDudley.\\n'I\\twant\\tmore\\tbacon.'\",\n",
       "  \"The\\tWorst\\tBirthday\\n'There's\\t more\\t in\\t the\\t frying\\t pan,\\t sweetums,'\\t said\\t Aunt\\t Petunia,\\t turning misty\\teyes\\ton\\ther\\tmassive\\tson.\\t'We\\tmust\\tfeed\\tyou\\tup\\twhile\\twe've\\tgot\\tthe chance\\t…\\tI\\tdon't\\tlike\\tthe\\tsound\\tof\\tthat\\tschool\\tfood\\t…'\\n'Nonsense,\\t Petunia,\\t I\\t never\\t went\\t hungry\\t when\\t I\\t was\\t at\\t Smeltings,'\\t said Uncle\\tVernon\\theartily.\\t'Dudley\\tgets\\tenough,\\tdon't\\tyou,\\tson?'\\nDudley,\\t who\\t was\\t so\\t large\\t his\\t bottom\\t drooped\\t over\\t either\\t side\\t of\\t the kitchen\\tchair,\\tgrinned\\tand\\tturned\\tto\\tHarry.\\n'Pass\\tthe\\tfrying\\tpan.'\\n'You've\\tforgotten\\tthe\\tmagic\\tword,'\\tsaid\\tHarry\\tirritably.\\nThe\\teffect\\tof\\tthis\\tsimple\\tsentence\\ton\\tthe\\trest\\tof\\tthe\\tfamily\\twas\\tincredible: Dudley\\t gasped\\t and\\t fell\\t off\\t his\\t chair\\t with\\t a\\t crash\\t that\\t shook\\t the\\t whole kitchen;\\t Mrs\\t Dursley\\t gave\\t a\\t small\\t scream\\t and\\t clapped\\t her\\t hands\\t to\\t her mouth;\\tMr\\tDursley\\tjumped\\tto\\this\\tfeet,\\tveins\\tthrobbing\\tin\\this\\ttemples.\\n'I\\tmeant\\t'please'!'\\tsaid\\tHarry\\tquickly.\\t'I\\tdidn't\\tmean\\t-'\",\n",
       "  \"The\\tWorst\\tBirthday\\n'WHAT\\tHAVE\\tI\\tTOLD\\tYOU,'\\tthundered\\this\\tuncle,\\tspraying\\tspit\\tover\\tthe table,\\t'ABOUT\\tSAYING\\tTHE\\tM\\tWORD\\tIN\\tOUR\\tHOUSE?'\\n'But\\tI\\t-'\\n'HOW\\t DARE\\t YOU\\t THREATEN\\t DUDLEY!'\\t roared\\t Uncle\\t Vernon, pounding\\tthe\\ttable\\twith\\this\\tfist.\\n'I\\tjust\\t-'\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nHarry\\tstared\\tfrom\\this\\tpurple-faced\\tuncle\\tto\\this\\tpale\\taunt,\\twho\\twas\\ttrying\\tto heave\\tDudley\\tto\\this\\tfeet.\\n'All\\tright,'\\tsaid\\tHarry, 'all\\tright\\t…'\\nUncle\\t Vernon\\t sat\\t back\\t down,\\t breathing\\t like\\t a\\t winded\\t rhinoceros\\t and watching\\tHarry\\tclosely\\tout\\tof\\tthe\\tcorners\\tof\\this\\tsmall,\\tsharp\\teyes.\\nEver\\tsince\\tHarry\\thad\\tcome\\thome\\tfor\\tthe\\tsummer\\tholidays,\\tUncle\\tVernon had\\tbeen\\ttreating\\thim\\tlike\\ta\\tbomb\\tthat\\tmight\\tgo\\toff\\tat\\tany\\tmoment,\\tbecause Harry wasn't a\\tnormal\\tboy.\\tAs\\ta\\tmatter\\tof\\tfact,\\the\\twas\\tas\\tnot\\tnormal\\tas\\tit\\tis possible\\tto\\tbe.\\nHarry\\tPotter\\twas\\ta\\twizard\\t-\\ta\\twizard\\tfresh\\tfrom\\this\\tfirst\\tyear\\tat\\tHogwarts School\\t of\\t Witchcraft\\t and\\t Wizardry.\\t And\\t if\\t the\\t Dursleys\\t were\\t unhappy\\t to have\\thim\\tback\\tfor\\tthe\\tholidays,\\tit\\twas\\tnothing\\tto\\thow\\tHarry\\tfelt.\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nHe\\tmissed\\tHogwarts\\tso\\tmuch\\tit\\twas\\tlike\\thaving\\ta\\tconstant\\tstomach\\tache. He\\t missed\\t the\\t castle,\\t with\\t its\\t secret\\t passageways\\t and\\t ghosts,\\t his\\t lessons (though\\t perhaps\\t not\\t Snape,\\t the\\t Potions\\t master),\\t the\\t post\\t arriving\\t by\\t owl, eating\\tbanquets\\tin\\tthe\\tGreat\\tHall,\\tsleeping\\tin\\this\\tfour-poster\\tbed\\tin\\tthe\\ttower dormitory,\\tvisiting\\tthe\\tgamekeeper,\\tHagrid,\\tin\\this\\tcabin\\tin\\tthe\\tgrounds\\tnext\\tto the\\tForbidden\\tForest\\tand,\\tespecially,\\tQuidditch,\\tthe\\tmost\\tpopular\\tsport\\tin\\tthe wizarding\\tworld\\t(six\\ttall\\tgoalposts,\\tfour\\tflying\\tballs\\tand\\tfourteen\\tplayers\\ton broomsticks).\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nAll\\t Harry's\\t spellbooks,\\t his\\t wand,\\t robes,\\t cauldron\\t and\\t top-of-the-range Nimbus\\tTwo\\tThousand\\tbroomstick\\thad\\tbeen\\tlocked\\tin\\ta\\tcupboard\\tunder\\tthe stairs\\t by\\t Uncle\\t Vernon\\t the\\t instant\\t Harry\\t had\\t come\\t home.\\t What\\t did\\t the Dursleys\\tcare\\tif\\tHarry\\tlost\\this\\tplace\\tin\\tthe\\thouse\\tQuidditch\\tteam\\tbecause\\the hadn't\\tpractised\\tall\\tsummer?\\tWhat\\twas\\tit\\tto\\tthe\\tDursleys\\tif\\tHarry\\twent\\tback to\\t school\\t without\\t any\\t of\\t his\\t homework\\t done?\\t The\\t Dursleys\\t were\\t what wizards\\tcalled\\tMuggles\\t(not\\ta\\tdrop\\tof\\tmagical\\tblood\\tin\\ttheir\\tveins)\\tand\\tas\\tfar as\\tthey\\twere\\tconcerned,\\thaving\\ta\\twizard\\tin\\tthe\\tfamily\\twas\\ta\\tmatter\\tof\\tdeepest shame.\\t Uncle\\t Vernon\\t had\\t even\\t padlocked\\t Harry's\\t owl,\\t Hedwig,\\t inside\\t her cage,\\tto\\tstop\\ther\\tcarrying\\tmessages\\tto\\tanyone\\tin\\tthe\\twizarding\\tworld.\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nHarry\\tlooked\\tnothing\\tlike\\tthe\\trest\\tof\\tthe\\tfamily.\\tUncle\\tVernon\\twas\\tlarge and\\tneckless,\\twith\\tan\\tenormous\\tblack\\tmoustache;\\tAunt\\tPetunia\\twas\\thorse- faced\\tand\\tbony;\\tDudley\\twas\\tblond,\\tpink\\tand\\tporky.\\tHarry,\\ton\\tthe\\tother\\thand, was\\t small\\t and\\t skinny,\\t with\\t brilliant\\t green\\t eyes\\t and\\t jet-black\\t hair\\t that\\t was always\\t untidy.\\t He\\t wore\\t round\\t glasses,\\t and\\t on\\t his\\t forehead\\t was\\t a\\t thin, lightning-shaped\\tscar.\\nIt\\twas\\tthis\\tscar\\tthat\\tmade\\tHarry\\tso\\tparticularly\\tunusual,\\teven\\tfor\\ta\\twizard. This\\tscar\\twas\\tthe\\tonly\\thint\\tof\\tHarry's\\tvery\\tmysterious\\tpast,\\tof\\tthe\\treason\\the had\\tbeen\\tleft\\ton\\tthe\\tDursleys'\\tdoorstep\\televen\\tyears\\tbefore.\"],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [None, None, None, None, None, None, None, None, None, None]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_built.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "76XSwG0bxvd1"
   },
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db, n_results=3):\n",
    "  \"\"\"Get relevant passages with better error handling\"\"\"\n",
    "\n",
    "  try:\n",
    "    results=db.query(query_texts=[query], n_results=n_results)\n",
    "    if not results['documents']:\n",
    "      print(\"No results found\")\n",
    "      return None\n",
    "    return results['documents'][0]\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error in query: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_Q-CKJqxyH6",
    "outputId": "188d08ec-8b9c-4daf-8d9f-07d0eb13182b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'The what? '\\n'It's\\tall\\tto\\tdo\\twith\\tbewitching\\tthings\\tthat\\tare\\tMuggle-made,\\tyou\\tknow,\\tin case\\tthey\\tend\\tup\\tback\\tin\\ta\\tMuggle\\tshop\\tor\\thouse.\\tLike,\\tlast\\tyear,\\tsome\\told witch\\tdied\\tand\\ther\\ttea\\tset\\twas\\tsold\\tto\\tan\\tantiques\\tshop.\\tThis\\tMuggle\\twoman bought\\t it,\\t took\\t it\\t home\\t and\\t tried\\t to\\t serve\\t her\\t friends\\t tea\\t in\\t it.\\t It\\t was\\t a nightmare\\t-\\tDad\\twas\\tworking\\tovertime\\tfor\\tweeks.'\", \"Owl\\tPost\\nNon-magic people (more commonly known as Muggles) were particularly\\t afraid\\t of\\t magic\\t in\\t medieval\\t times,\\t but\\t not\\t very\\t good\\t at recognising\\tit.\\tOn\\tthe\\trare\\toccasion\\tthat\\tthey\\tdid\\tcatch\\ta\\treal\\twitch\\tor wizard,\\t burning\\t had\\t no\\t effect\\t whatsoever.\\t The\\t witch\\t or\\t wizard\\t would perform\\ta\\tbasic\\tFlame-Freezing\\tCharm\\tand\\tthen\\tpretend\\tto\\tshriek\\twith pain\\t while\\t enjoying\\t a\\t gentle,\\t tickling\\t sensation.\\t Indeed,\\t Wendelin\\t the Weird\\tenjoyed\\tbeing\\tburnt\\tso\\tmuch\\tthat\\tshe\\tallowed\\therself\\tto\\tbe\\tcaught no\\tfewer\\tthan\\tforty-seven\\ttimes\\tin\\tvarious\\tdisguises.\\nHarry\\tput\\this\\tquill\\tbetween\\this\\tteeth\\tand\\treached\\tunderneath\\this\\tpillow\\tfor\\this ink\\tbottle\\tand\\ta\\troll\\tof\\tparchment.\\tSlowly\\tand\\tvery\\tcarefully\\the\\tunscrewed the\\tink\\tbottle,\\tdipped\\this\\tquill\\tinto\\tit\\tand\\tbegan\\tto\\twrite,\\tpausing\\tevery\\tnow and\\tthen\\tto\\tlisten,\\tbecause\\tif\\tany\\tof\\tthe\\tDursleys\\theard\\tthe\\tscratching\\tof\\this quill\\ton\\ttheir\\tway\\tto\\tthe\\tbathroom,\\the'd\\tprobably\\tfind\\thimself\\tlocked\\tin\\tthe cupboard\\tunder\\tthe\\tstairs\\tfor\\tthe\\trest\\tof\\tthe\\tsummer.\", 'HARRY POTTER\\nVisit\\tpottermore.com\\nTo\\tJill\\tPrewett\\tand\\tAine\\tKiely, the\\tGodmothers\\tof\\tSwing']\n"
     ]
    }
   ],
   "source": [
    "# Perform embedding search\n",
    "passage = get_relevant_passage(\"What are muggles?\", collection_built)\n",
    "print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tINph130bSXk",
    "outputId": "63b0a8a0-c9a3-49db-aa1c-cc3f35771434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13281    0 13281    0     0  54192      0 --:--:-- --:--:-- --:--:-- 54430\n",
      ">>> Installing ollama to /usr/local\n",
      ">>> Downloading Linux amd64 bundle\n",
      "######################################################################## 100.0%\n",
      ">>> Creating ollama user...\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n"
     ]
    }
   ],
   "source": [
    "!curl https://ollama.ai/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uQ7l_6YucA_W"
   },
   "outputs": [],
   "source": [
    "!nohup ollama serve > ollama.log 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Hpipu3ocExq",
    "outputId": "f2554597-849a-4e63-9af3-52f18a891633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25hThe\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Netherlands\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h **\u001b[?25l\u001b[?25hAmsterdam\u001b[?25l\u001b[?25h**.\u001b[?25l\u001b[?25h \u001b[?25l\u001b[?25h\n",
      "\n",
      "\u001b[?25l\u001b[?25hWhile\u001b[?25l\u001b[?25h The\u001b[?25l\u001b[?25h Hague\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h seat\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h government\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h Amsterdam\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h city\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h 😊\u001b[?25l\u001b[?25h \u001b[?25l\u001b[?25h\n",
      "\u001b[?25l\u001b[?25h\n",
      "\n",
      "\u001b[?25l\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! ollama run gemma3n:latest “What is the capital of the Netherlands?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXQL6qzSdjBV",
    "outputId": "cdfa4bde-1266-4348-b2ed-32a757fabe67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "gBedAp4zFYk2"
   },
   "outputs": [],
   "source": [
    "# send the query to ollama gemma3n model\n",
    "import ollama\n",
    "def send_response_to_ollama(response, model_name='gemma3n:latest'):\n",
    "  client= ollama.Client()\n",
    "\n",
    "  prompt= f\"\"\"You are a Harry Potter expert specializing in the first three books: Philosopher's Stone, Chamber of Secrets, and Prisoner of Azkaban.\n",
    "\n",
    "  Your task: A user asked a question about Harry Potter, and our system retrieved the following relevant passages from the novels. Based on these passages, provide a comprehensive answer that directly addresses what the user likely asked.\n",
    "\n",
    "  Guidelines:\n",
    "  - Write a clear, informative answer in 50-150 words\n",
    "  - Focus on the key information from the retrieved passages\n",
    "  - Maintain the magical tone of the Harry Potter universe\n",
    "  - If multiple concepts are mentioned, prioritize the most relevant ones\n",
    "  - Don't speculate beyond what's provided in the retrieved text\n",
    "\n",
    "\n",
    "  Retrieved Information:\n",
    "  {response}\n",
    "\n",
    "  Summary: \"\"\"\n",
    "\n",
    "  try:\n",
    "    response= ollama.chat(\n",
    "        model= model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "            }\n",
    "        ],\n",
    "        options={\n",
    "            'temperature': 0.3,\n",
    "            'max_tokens': 250,\n",
    "            'top_p': 0.5\n",
    "        }\n",
    "\n",
    "    )\n",
    "    return response['message']['content']\n",
    "  except Exception as e:\n",
    "    print(f\"Error in ollama chat: {e}\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "R9ZOprxgfejj"
   },
   "outputs": [],
   "source": [
    "final_response= send_response_to_ollama(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "0A8PNFonfwpo",
    "outputId": "85f1bc74-b7c2-4358-fd31-83051c229757"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The passages reveal intriguing details about the world of magic and its interactions with the Muggle world. It seems that Muggles, or non-magic people, often fear magic, though they aren't adept at recognizing it. Attempts to harm wizards or witches with fire are futile, as they can employ a basic Flame-Freezing Charm. \\n\\nFurthermore, there's a concern about magical objects ending up in Muggle possession, as illustrated by the story of an old witch's tea set. Harry Potter is shown carefully writing with quill and ink, taking precautions to avoid being discovered by the Dursley family. \\n\\nThese snippets offer a glimpse into the complexities of a world where magic and the mundane coexist, with its own set of rules and hidden dangers.\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
