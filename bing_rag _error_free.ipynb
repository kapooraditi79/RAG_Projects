{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I ran my file in colab. But due to some technical issues, I was unable to upload it via colab. So I have downloaded a copy in my vs code and i am uploading it from there. But all the settings are as per colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24PQnY1i0-rj"
   },
   "source": [
    "Referenced Sites:\n",
    "* https://docling-project.github.io/docling/examples/hybrid_chunking/#overview\n",
    "\n",
    "* https://www.youtube.com/watch?v=9lBTS5dM27c&list=WL&index=2&t=1s\n",
    "\n",
    "* Contextual Chunking-> https://www.anthropic.com/news/contextual-retrieval\n",
    "\n",
    "* LanceDB embeddings-> https://lancedb.github.io/lancedb/embeddings/default_embedding_functions/#text-embedding-functions\n",
    "\n",
    "I am doing text embeddings only. Not multi-modal embeddings.\n",
    "\n",
    "* Building with Google's gemini embeddings-> https://lancedb.github.io/lancedb/embeddings/available_embedding_models/text_embedding_functions/gemini_embedding/\n",
    "\n",
    "* https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb \n",
    "\n",
    "* https://ai.google.dev/gemini-api/docs/embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rRU40ieyLoG"
   },
   "outputs": [],
   "source": [
    "! pip install docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NMag9RGuySXL"
   },
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "converter= DocumentConverter()\n",
    "\n",
    "result= converter.convert('combined_markdown.md')\n",
    "result= result.document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3R9hQOg29Nbh"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILEfGCYLyDMG",
    "outputId": "3f72d485-c78a-4814-c509-8ed0589ef680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0GSBLJMEy1X0"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "token= userdata.get('HF_TOKEN_ORIGINAL_AGENTCOURSE')\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fC371pyurN2"
   },
   "source": [
    "Setting up the configurations of bitsAndBytes config.\n",
    "\n",
    "Note-> the latest version ,when i made this notebook, of bitsandbytes==0.46 is supported by only cuda==12.3. while the latest version of cuda is 12.4.\n",
    "So i made the following changes. make these changes only after a proper research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kQ1G9yluf1B"
   },
   "outputs": [],
   "source": [
    "# 1. Clean broken bitsandbytes installs\n",
    "! pip uninstall -y bitsandbytes\n",
    "! rm -rf /usr/local/lib/python*/dist-packages/bitsandbytes*\n",
    "\n",
    "# 2. Set the manual override for CUDA 12.3\n",
    "import os\n",
    "os.environ[\"BNB_CUDA_VERSION\"] = \"123\"\n",
    "\n",
    "# 3. Reinstall the latest bitsandbytes (supports 12.3)\n",
    "! pip install bitsandbytes\n",
    "! pip install -U transformers accelerate\n",
    "\n",
    "# 4. Verify CUDA backend\n",
    "! python -m bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "bd49bcd336ea476a8637efd6739ad1ac",
      "42b5fa3d09cf4ed18f61c1016e4751fa",
      "4de77b5134764500a472a25c1dc45405",
      "8a7ff78403134e1db6c9e794bbb70927",
      "7182df38857b4c3eba6851d05feced8c",
      "2e25339abf1641e682916ec72b8008a3",
      "a8d14d7dce6c4f66b20f94456540df70",
      "02ba0b240c354b13857c7cc452a058a9",
      "d07b6ee26ac24c67ac86e9398b9286b5",
      "5edf159f78de4d7a9cdc962def67d35e",
      "6ca703c3c4a342fc944ae9f38c8fb89c",
      "925a152930944616869a35b70aa76c7b",
      "73edafaae6fa4d15b66e905cc49cc4ce",
      "34e2c1e69c8548c8ab0826ad4dd361df",
      "95f1852f7eb246068e80279b552ff512",
      "b315f9d4c9864c398a6d52b95fda369d",
      "cf35b511d31641efbfedca614594cc38",
      "df12190513eb4441879ca0607dc047b3",
      "3e181325141045efb278448fc34476f3",
      "62a141ebc93e455eac4a508588d3ff50",
      "14760c7db9b24b75a70c17619381bb10",
      "d62ba77014b14f9cbe706e9d23edb9ab",
      "e49fda1fb09443f38daa4dd7dcd59246",
      "4f329ab1f54a4e0794a8325de983d7b3",
      "fe5a98d899f44af6b1c547be112eb134",
      "6c1fbc7faa47493184613908ff8dc32f",
      "fb5506236bbf45adb1d51f9d9cdcba74",
      "c8a8f804f2494c44b2472f73583aab56",
      "50c098e7c3434b9db05c0218c7d7d549",
      "be67bc0be4744d5bb2ac4333acd108ef",
      "c0cccf91f549427ba8e7caa9418edaa5",
      "acbe9b068b384593b60a7ce94a0687a8",
      "8fb4a07352e24cd6b1c478614f56aa8c"
     ]
    },
    "id": "g-QSVDt7yKsA",
    "outputId": "0b247483-c8c4-4a83-e8ee-2ee2fcd8bef2"
   },
   "outputs": [],
   "source": [
    "# loading the model for tokenizing\n",
    "\n",
    "from transformers import BitsAndBytesConfig, Gemma3ForCausalLM\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "model = Gemma3ForCausalLM.from_pretrained(\n",
    "    \"google/gemma-3-1b-it\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuxGftZ1yrJz",
    "outputId": "526372e5-f23f-4dba-9c58-b04a2db5b077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# let us work on the chunking using docling\n",
    "%pip install -qU pip docling transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVPaew7k4I51"
   },
   "outputs": [],
   "source": [
    "# if you want to use the hugging face tokenizers\n",
    "! pip install 'docling-core[chunking]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CzPLjVh2gMa"
   },
   "source": [
    "In RAG it is important to make sure that the chunker and the embedding model are using the same tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsPxmUrz6tFY"
   },
   "source": [
    "okay so currently i do not see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "1665d85db37b4b369df9145910e52227",
      "bd22c7c36902419381443a7832d7b954",
      "e29dbcfba9a749379f6974ef6226f378",
      "68ce1cc9f0d743298431623f64a52576",
      "6ed0f76318d94e188f1566f5617ec8fe",
      "7fa1c6aa22fd45c4ac50f7819fdd2c65",
      "a9a231c3ccca4a2eaf3ff317cd8181a4",
      "d93dcb4794e24bcebe50f9a36d006b90",
      "43ca41ac3f7a43f4a3dbd7d2e6cfac72",
      "e03d597ac3e64e1697af49f4be6ed2fd",
      "91ad8c5820794f78b5cbd17c93225014",
      "94b2b147939946929e7f742727c04396",
      "8d49b587ca7b4051831cad379cbbb2a9",
      "c10493a018344623876ffd8c00afe371",
      "b1fb2aee6ddb4042a180dd9dd4a26dc9",
      "b0a886097a29457a8ce4010149062d46",
      "0dd1b662e4584b248aa7af921b343208",
      "b3d47449b0964d209af07fe1acf53472",
      "7cbf19a218944191a38ad838c2ffcabc",
      "c0ce0691bdba43d5ac815750861ea2bc",
      "074a2df52ef04e2390ec007197c4c4d9",
      "827fa8b7ab6141b5b8b25a4f8e8d8f56",
      "4628b95fc30346e0bb4e6b21c32e7d3f",
      "4ec962781f314605b4d9759756e4b37f",
      "8cadd83446f54e8fb8979680182210a9",
      "b04c4d18d7414530b6d4d62c1eeef26c",
      "4bb0de03b7e34811999267565bb143f2",
      "b86bea624e014051955c98da7e6b02f3",
      "5a4148148ea6439fa4899a3c6379405a",
      "f2cce4a1370d4dbda8216345ec8912c6",
      "91b388073f2b42e8a6b547c5805b323d",
      "b4edbbdcb7f94bf7b15de33e0345df41",
      "252c360ed37446d6a28b16f127973f75",
      "2bcdaca2750f4e2cbb68ba34e58ec3b2",
      "86eae2e9ed664dc0ab2a8923393e2d18",
      "801ab3007f4a40e0a39ebd8868cd1cb3",
      "30aeb5fe95dc48aab3ddd31bdb93c7a7",
      "45f5c2ea3e944ab6abeea017549cfd9e",
      "76e59dbc4b4c4505bd56fe21f0466d0c",
      "9d30696dc55744f28814904ae54cb95d",
      "994ba9e631644417a82dcbb68a2c8f03",
      "c13a64ec7dc94446bd708fd0a17bb75f",
      "4b22a598ab1c4f0a94b1961d6a9c4d0b",
      "99d756260ae641a9922324a6f41a5d90",
      "7ea99a44ed6647e4aeb5f5eba1fa26d9",
      "877179462f884b228e6fc10da1052afb",
      "5d88c3d11ad8424a9c4cb00ec471c332",
      "06f7f70a7adc429db64bf434488c92db",
      "db74ba8123b7456b967c4ece63488931",
      "8fdf990821d148b09c13e47283032147",
      "cfb254fba8c049148bda42bb102746d9",
      "6ec0b6fc543e40b6a923a0f550dcacf6",
      "e3d23c881f344705987f7afc4ba9273e",
      "f6918b2c669b4cc5978c131dbcf6f9e1",
      "98e3271e59774237b54bf4f37ce72afc"
     ]
    },
    "id": "EsloMcg_zdGr",
    "outputId": "f9e8ceb0-f407-4ba6-d0e9-b3e1d637935b"
   },
   "outputs": [],
   "source": [
    "# lets build our tokenizer\n",
    "from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "model_id= \"google/gemma-3-1b-it\"\n",
    "\n",
    "max_tokens= 400\n",
    "\n",
    "tokenizer= HuggingFaceTokenizer(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_id),\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IkZ0EDGq4eRL"
   },
   "outputs": [],
   "source": [
    "# now we can build our chunker\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "chunker= HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    merge_peers= True # merges the undersized chunks that share the same headings or metadata\n",
    ")\n",
    "\n",
    "def build_and_get_chunks(doc):\n",
    "  chunk_iter= chunker.chunk(doc)\n",
    "  chunks= list(chunk_iter)\n",
    "\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8eY9P7Oy-uIt"
   },
   "outputs": [],
   "source": [
    "chunks= build_and_get_chunks(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17Ueq0nx9yRV"
   },
   "source": [
    "we want to embed the contextualized chunkings. so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "racuIXEE9R3s"
   },
   "outputs": [],
   "source": [
    "def get_contextualized_chunks(chunks):\n",
    "  contextualized_chunks= []\n",
    "  for chunk in chunks:\n",
    "    enriched_text= chunker.contextualize(chunk=chunk)\n",
    "    contextualized_chunks.append(enriched_text)\n",
    "  return contextualized_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c-X04UYk-tIZ"
   },
   "outputs": [],
   "source": [
    "contextualized_chunk_list= get_contextualized_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "c1kgs2oUNCvO",
    "outputId": "44dff36e-6213-4817-a209-ac999bb4d80c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Dear\\tRon,\\tand\\tHarry\\tif\\tyou're\\tthere,\\nDraco\\tturned\\taway\\tand\\tsaw\\tthe\\tcabinet\\tright\\tin\\tfront\\tof\\thim.\\tHe\\twalked forward\\t\u2026\\the\\tstretched\\tout\\this\\thand\\tfor\\tthe\\thandle\\t\u2026\\n'Done,'\\tsaid\\tMr\\tMalfoy\\tat\\tthe\\tcounter.\\t'Come,\\tDraco!'\\nHarry\\twiped\\this\\tforehead\\ton\\this\\tsleeve\\tas\\tDraco\\tturned\\taway.\\n'Good\\tday\\tto\\tyou,\\tMr\\tBorgin,\\tI'll\\texpect\\tyou\\tat\\tthe\\tmanor\\ttomorrow\\tto pick\\tup\\tthe\\tgoods.'\\nThe\\tmoment\\tthe\\tdoor\\thad\\tclosed,\\tMr\\tBorgin\\tdropped\\this\\toily\\tmanner.\\n'Good\\tday\\tyourself, Mister Malfoy,\\tand\\tif\\tthe\\tstories\\tare\\ttrue,\\tyou\\thaven't sold\\tme\\thalf\\tof\\twhat's\\thidden\\tin\\tyour manor \u2026'\\nMuttering\\tdarkly,\\tMr\\tBorgin\\tdisappeared\\tinto\\ta\\tback\\troom.\\tHarry\\twaited for\\ta\\tminute\\tin\\tcase\\the\\tcame\\tback,\\tthen,\\tquietly\\tas\\the\\tcould,\\tslipped\\tout\\tof\\tthe cabinet,\\tpast\\tthe\\tglass\\tcases\\tand\\tout\\tof\\tthe\\tshop\\tdoor.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualized_chunk_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2zx8WtoOp1ja"
   },
   "outputs": [],
   "source": [
    "! pip install -U -q 'google-genai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "G7Ns4Eijb1rF"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client=genai.Client(api_key=userdata.get('GOOGLE_2_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYGIdSrGisHV"
   },
   "outputs": [],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dDZdrbWuomQ9"
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "    # required by chromadb\n",
    "\n",
    "\n",
    "  def __call__(self, input:Documents) -> Embeddings:\n",
    "    Embedding_Model_ID= \"models/text-embedding-004\"\n",
    "\n",
    "    # ensuring input is formatted\n",
    "    if isinstance(input, str):\n",
    "      input= [input]\n",
    "\n",
    "    all_embeddings=[]\n",
    "    batch_size=100\n",
    "\n",
    "    for i in range(0, len(input), batch_size):\n",
    "      batch= input[i:i+batch_size]\n",
    "      try:\n",
    "        response= client.models.embed_content(\n",
    "            model=Embedding_Model_ID,\n",
    "            contents= input,\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type='retrieval_document',\n",
    "\n",
    "            )\n",
    "        )\n",
    "        # return all teh embeddings\n",
    "        batch_embeddings= [emb.values for emb in response.embeddings]\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f\"Embedding error:{e}\")\n",
    "        return None\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "I4m_jTWhqWpF"
   },
   "outputs": [],
   "source": [
    "# fix chromadb for batch processing\n",
    "import chromadb\n",
    "def create_chroma_db(contextualized_chunk_list):\n",
    "  chroma_client= chromadb.PersistentClient(path=\"novel_collection_embeddings_3\")\n",
    "\n",
    "  collection= chroma_client.get_or_create_collection(\n",
    "      name='bing_novelrag_collection_3',\n",
    "      embedding_function=GeminiEmbeddingFunction()\n",
    "  )\n",
    "  print(f\"Adding {len(contextualized_chunk_list)} chunks to database...\")\n",
    "\n",
    "  # add documents in batches to avoid memory issues\n",
    "  batch_size=50\n",
    "\n",
    "  for i in range(0, len(contextualized_chunk_list), batch_size):\n",
    "    end_idx= min(i+batch_size, len(contextualized_chunk_list))\n",
    "    batch_docs= contextualized_chunk_list[i:end_idx]\n",
    "    batch_ids= [str(j) for j in range(i, end_idx)]\n",
    "\n",
    "\n",
    "    collection.add(\n",
    "        documents= batch_docs,\n",
    "        ids= batch_ids\n",
    "    )\n",
    "\n",
    "    print(f\"Added batch {i//batch_size + 1}/{(len(contextualized_chunk_list)+ batch_size - 1)//batch_size}\")\n",
    "\n",
    "\n",
    "  print(f\"Database created with {collection.count()} documents\")\n",
    "\n",
    "  return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tx3gdlb5rULX",
    "outputId": "32cc1f86-bf9a-4c76-e93e-d870266d7498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 1346 chunks to database...\n",
      "Added batch 1/27\n",
      "Added batch 2/27\n",
      "Added batch 3/27\n",
      "Added batch 4/27\n",
      "Added batch 5/27\n",
      "Added batch 6/27\n",
      "Added batch 7/27\n",
      "Added batch 8/27\n",
      "Added batch 9/27\n",
      "Added batch 10/27\n",
      "Added batch 11/27\n",
      "Added batch 12/27\n",
      "Added batch 13/27\n",
      "Added batch 14/27\n",
      "Added batch 15/27\n",
      "Added batch 16/27\n",
      "Added batch 17/27\n",
      "Added batch 18/27\n",
      "Added batch 19/27\n",
      "Added batch 20/27\n",
      "Added batch 21/27\n",
      "Added batch 22/27\n",
      "Added batch 23/27\n",
      "Added batch 24/27\n",
      "Added batch 25/27\n",
      "Added batch 26/27\n",
      "Added batch 27/27\n",
      "Database created with 1346 documents\n"
     ]
    }
   ],
   "source": [
    "# Set up the DB\n",
    "collection_built = create_chroma_db(contextualized_chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOJJTDIAxRoq",
    "outputId": "e794c423-9a78-4eee-8149-3e7ca1128dfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       " 'embeddings': array([[-0.03861213,  0.02344161, -0.00374704, ...,  0.00964072,\n",
       "          0.0244747 , -0.01426351],\n",
       "        [-0.02072495,  0.02093361, -0.00411656, ...,  0.05033953,\n",
       "         -0.00417255, -0.02308157],\n",
       "        [-0.0383333 ,  0.01372326, -0.02511429, ...,  0.06165662,\n",
       "          0.01992766,  0.00818526],\n",
       "        ...,\n",
       "        [-0.03405032,  0.00664998, -0.00151566, ...,  0.0002513 ,\n",
       "          0.04247424, -0.03012509],\n",
       "        [-0.05485309, -0.00544187,  0.01287586, ..., -0.02370497,\n",
       "          0.02652791, -0.02154174],\n",
       "        [-0.03307312, -0.00749543, -0.02514764, ...,  0.01036208,\n",
       "         -0.01646801, -0.03018571]]),\n",
       " 'documents': ['HARRY POTTER\\nand\\tthe\\tChamber\\tof\\tSecrets\\nJ.K.\\tROWLING\\nAll\\trights\\treserved;\\tno\\tpart\\tof\\tthis\\tpublication\\tmay\\tbe\\treproduced\\tor\\ttransmitted\\tby\\tany\\tmeans, electronic,\\tmechanical,\\tphotocopying\\tor\\totherwise,\\twithout\\tthe\\tprior\\tpermission\\tof\\tthe\\tpublisher\\nThis\\tdigital\\tedition\\tfirst\\tpublished\\tby\\tPottermore\\tLimited\\tin\\t2012\\nFirst\\tpublished\\tin\\tprint\\tin\\tGreat\\tBritain\\tin\\t1998\\tby\\tBloomsbury\\tPublishing\\tPlc\\nCopyright\\t\u00a9\\tJ.K.\\tRowling\\t1998\\nCover\\tillustrations\\tby\\tClaire\\tMelinsky\\tcopyright\\t\u00a9\\tJ.K.\\tRowling\\t2010\\nHarry\\tPotter\\tcharacters,\\tnames\\tand\\trelated\\tindicia\\tare\\ttrademarks\\tof\\tand\\t\u00a9\\tWarner\\tBros.\\tEnt.\\nThe\\tmoral\\tright\\tof\\tthe\\tauthor\\thas\\tbeen\\tasserted\\nA\\tCIP\\tcatalogue\\trecord\\tof\\tthis\\tbook\\tis\\tavailable\\tfrom\\tthe\\tBritish\\tLibrary\\nISBN\\t978-1-78110-008-0\\nwww.pottermore.com\\nby\\tJ.K.\\tRowling\\nThe\\tunique\\tonline\\texperience\\tbuilt\\taround\\tthe\\tHarry\\tPotter\\tbooks.\\tShare\\tand participate\\tin\\tthe\\tstories,\\tshowcase\\tyour\\town\\tPotter-related\\tcreativity\\tand discover\\teven\\tmore\\tabout\\tthe\\tworld\\tof\\tHarry\\tPotter\\tfrom\\tthe\\tauthor\\therself.\\nVisit\\tpottermore.com',\n",
       "  'HARRY POTTER\\nFor\\tS\u00e9an\\tP.F.\\tHarris, getaway\\tdriver\\tand\\tfoulweather\\tfriend',\n",
       "  \"CONTENTS\\nONE The\\tWorst\\tBirthday\\nTWO Dobby's\\tWarning\\nTHREE The\\tBurrow\\nFOUR At\\tFlourish\\tand\\tBlotts\\nFIVE The\\tWhomping\\tWillow\\nSIX Gilderoy\\tLockhart\\nSEVEN Mudbloods\\tand\\tMurmurs\\nEIGHT The\\tDeathday\\tParty\\nNINE The\\tWriting\\ton\\tthe\\tWall\\nTEN The\\tRogue\\tBludger\\nELEVEN The\\tDuelling\\tClub\\nTWELVE The\\tPolyjuice\\tPotion\\nTHIRTEEN The\\tVery\\tSecret\\tDiary\\nFOURTEEN Cornelius\\tFudge\\nFIFTEEN Aragog\\nSIXTEEN The\\tChamber\\tof\\tSecrets\\nSEVENTEEN The\\tHeir\\tof\\tSlytherin\\nEIGHTEEN Dobby's\\tReward\",\n",
       "  \"The\\tWorst\\tBirthday\\nNot\\tfor\\tthe\\tfirst\\ttime,\\tan\\targument\\thad\\tbroken\\tout\\tover\\tbreakfast\\tat\\tnumber four,\\tPrivet\\tDrive.\\tMr\\tVernon\\tDursley\\thad\\tbeen\\twoken\\tin\\tthe\\tearly\\thours\\tof the\\tmorning\\tby\\ta\\tloud,\\thooting\\tnoise\\tfrom\\this\\tnephew\\tHarry's\\troom.\\n'Third\\ttime\\tthis\\tweek!'\\the\\troared\\tacross\\tthe\\ttable.\\t'If\\tyou\\tcan't\\tcontrol\\tthat owl,\\tit'll\\thave\\tto\\tgo!'\\nHarry\\ttried,\\tyet\\tagain,\\tto\\texplain.\\n'She's bored, '\\the\\tsaid.\\t'She's\\tused\\tto\\tflying\\taround\\toutside.\\tIf\\tI\\tcould\\tjust let\\ther\\tout\\tat\\tnight\\t\u2026'\\n'Do\\tI\\tlook\\tstupid?'\\tsnarled\\tUncle\\tVernon,\\ta\\tbit\\tof\\tfried\\tegg\\tdangling\\tfrom his\\tbushy\\tmoustache.\\t'I\\tknow\\twhat'll\\thappen\\tif\\tthat\\towl's\\tlet\\tout.'\\nHe\\texchanged\\tdark\\tlooks\\twith\\this\\twife,\\tPetunia.\\nHarry\\ttried\\tto\\targue\\tback\\tbut\\this\\twords\\twere\\tdrowned\\tby\\ta\\tlong,\\tloud\\tbelch from\\tthe\\tDursleys'\\tson,\\tDudley.\\n'I\\twant\\tmore\\tbacon.'\",\n",
       "  \"The\\tWorst\\tBirthday\\n'There's\\t more\\t in\\t the\\t frying\\t pan,\\t sweetums,'\\t said\\t Aunt\\t Petunia,\\t turning misty\\teyes\\ton\\ther\\tmassive\\tson.\\t'We\\tmust\\tfeed\\tyou\\tup\\twhile\\twe've\\tgot\\tthe chance\\t\u2026\\tI\\tdon't\\tlike\\tthe\\tsound\\tof\\tthat\\tschool\\tfood\\t\u2026'\\n'Nonsense,\\t Petunia,\\t I\\t never\\t went\\t hungry\\t when\\t I\\t was\\t at\\t Smeltings,'\\t said Uncle\\tVernon\\theartily.\\t'Dudley\\tgets\\tenough,\\tdon't\\tyou,\\tson?'\\nDudley,\\t who\\t was\\t so\\t large\\t his\\t bottom\\t drooped\\t over\\t either\\t side\\t of\\t the kitchen\\tchair,\\tgrinned\\tand\\tturned\\tto\\tHarry.\\n'Pass\\tthe\\tfrying\\tpan.'\\n'You've\\tforgotten\\tthe\\tmagic\\tword,'\\tsaid\\tHarry\\tirritably.\\nThe\\teffect\\tof\\tthis\\tsimple\\tsentence\\ton\\tthe\\trest\\tof\\tthe\\tfamily\\twas\\tincredible: Dudley\\t gasped\\t and\\t fell\\t off\\t his\\t chair\\t with\\t a\\t crash\\t that\\t shook\\t the\\t whole kitchen;\\t Mrs\\t Dursley\\t gave\\t a\\t small\\t scream\\t and\\t clapped\\t her\\t hands\\t to\\t her mouth;\\tMr\\tDursley\\tjumped\\tto\\this\\tfeet,\\tveins\\tthrobbing\\tin\\this\\ttemples.\\n'I\\tmeant\\t'please'!'\\tsaid\\tHarry\\tquickly.\\t'I\\tdidn't\\tmean\\t-'\",\n",
       "  \"The\\tWorst\\tBirthday\\n'WHAT\\tHAVE\\tI\\tTOLD\\tYOU,'\\tthundered\\this\\tuncle,\\tspraying\\tspit\\tover\\tthe table,\\t'ABOUT\\tSAYING\\tTHE\\tM\\tWORD\\tIN\\tOUR\\tHOUSE?'\\n'But\\tI\\t-'\\n'HOW\\t DARE\\t YOU\\t THREATEN\\t DUDLEY!'\\t roared\\t Uncle\\t Vernon, pounding\\tthe\\ttable\\twith\\this\\tfist.\\n'I\\tjust\\t-'\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nHarry\\tstared\\tfrom\\this\\tpurple-faced\\tuncle\\tto\\this\\tpale\\taunt,\\twho\\twas\\ttrying\\tto heave\\tDudley\\tto\\this\\tfeet.\\n'All\\tright,'\\tsaid\\tHarry, 'all\\tright\\t\u2026'\\nUncle\\t Vernon\\t sat\\t back\\t down,\\t breathing\\t like\\t a\\t winded\\t rhinoceros\\t and watching\\tHarry\\tclosely\\tout\\tof\\tthe\\tcorners\\tof\\this\\tsmall,\\tsharp\\teyes.\\nEver\\tsince\\tHarry\\thad\\tcome\\thome\\tfor\\tthe\\tsummer\\tholidays,\\tUncle\\tVernon had\\tbeen\\ttreating\\thim\\tlike\\ta\\tbomb\\tthat\\tmight\\tgo\\toff\\tat\\tany\\tmoment,\\tbecause Harry wasn't a\\tnormal\\tboy.\\tAs\\ta\\tmatter\\tof\\tfact,\\the\\twas\\tas\\tnot\\tnormal\\tas\\tit\\tis possible\\tto\\tbe.\\nHarry\\tPotter\\twas\\ta\\twizard\\t-\\ta\\twizard\\tfresh\\tfrom\\this\\tfirst\\tyear\\tat\\tHogwarts School\\t of\\t Witchcraft\\t and\\t Wizardry.\\t And\\t if\\t the\\t Dursleys\\t were\\t unhappy\\t to have\\thim\\tback\\tfor\\tthe\\tholidays,\\tit\\twas\\tnothing\\tto\\thow\\tHarry\\tfelt.\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nHe\\tmissed\\tHogwarts\\tso\\tmuch\\tit\\twas\\tlike\\thaving\\ta\\tconstant\\tstomach\\tache. He\\t missed\\t the\\t castle,\\t with\\t its\\t secret\\t passageways\\t and\\t ghosts,\\t his\\t lessons (though\\t perhaps\\t not\\t Snape,\\t the\\t Potions\\t master),\\t the\\t post\\t arriving\\t by\\t owl, eating\\tbanquets\\tin\\tthe\\tGreat\\tHall,\\tsleeping\\tin\\this\\tfour-poster\\tbed\\tin\\tthe\\ttower dormitory,\\tvisiting\\tthe\\tgamekeeper,\\tHagrid,\\tin\\this\\tcabin\\tin\\tthe\\tgrounds\\tnext\\tto the\\tForbidden\\tForest\\tand,\\tespecially,\\tQuidditch,\\tthe\\tmost\\tpopular\\tsport\\tin\\tthe wizarding\\tworld\\t(six\\ttall\\tgoalposts,\\tfour\\tflying\\tballs\\tand\\tfourteen\\tplayers\\ton broomsticks).\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nAll\\t Harry's\\t spellbooks,\\t his\\t wand,\\t robes,\\t cauldron\\t and\\t top-of-the-range Nimbus\\tTwo\\tThousand\\tbroomstick\\thad\\tbeen\\tlocked\\tin\\ta\\tcupboard\\tunder\\tthe stairs\\t by\\t Uncle\\t Vernon\\t the\\t instant\\t Harry\\t had\\t come\\t home.\\t What\\t did\\t the Dursleys\\tcare\\tif\\tHarry\\tlost\\this\\tplace\\tin\\tthe\\thouse\\tQuidditch\\tteam\\tbecause\\the hadn't\\tpractised\\tall\\tsummer?\\tWhat\\twas\\tit\\tto\\tthe\\tDursleys\\tif\\tHarry\\twent\\tback to\\t school\\t without\\t any\\t of\\t his\\t homework\\t done?\\t The\\t Dursleys\\t were\\t what wizards\\tcalled\\tMuggles\\t(not\\ta\\tdrop\\tof\\tmagical\\tblood\\tin\\ttheir\\tveins)\\tand\\tas\\tfar as\\tthey\\twere\\tconcerned,\\thaving\\ta\\twizard\\tin\\tthe\\tfamily\\twas\\ta\\tmatter\\tof\\tdeepest shame.\\t Uncle\\t Vernon\\t had\\t even\\t padlocked\\t Harry's\\t owl,\\t Hedwig,\\t inside\\t her cage,\\tto\\tstop\\ther\\tcarrying\\tmessages\\tto\\tanyone\\tin\\tthe\\twizarding\\tworld.\",\n",
       "  \"'I\\t WARNED\\t YOU!\\t I\\t WILL\\t NOT\\t TOLERATE\\t MENTION\\t OF\\t YOUR ABNORMALITY\\tUNDER\\tTHIS\\tROOF!'\\nHarry\\tlooked\\tnothing\\tlike\\tthe\\trest\\tof\\tthe\\tfamily.\\tUncle\\tVernon\\twas\\tlarge and\\tneckless,\\twith\\tan\\tenormous\\tblack\\tmoustache;\\tAunt\\tPetunia\\twas\\thorse- faced\\tand\\tbony;\\tDudley\\twas\\tblond,\\tpink\\tand\\tporky.\\tHarry,\\ton\\tthe\\tother\\thand, was\\t small\\t and\\t skinny,\\t with\\t brilliant\\t green\\t eyes\\t and\\t jet-black\\t hair\\t that\\t was always\\t untidy.\\t He\\t wore\\t round\\t glasses,\\t and\\t on\\t his\\t forehead\\t was\\t a\\t thin, lightning-shaped\\tscar.\\nIt\\twas\\tthis\\tscar\\tthat\\tmade\\tHarry\\tso\\tparticularly\\tunusual,\\teven\\tfor\\ta\\twizard. This\\tscar\\twas\\tthe\\tonly\\thint\\tof\\tHarry's\\tvery\\tmysterious\\tpast,\\tof\\tthe\\treason\\the had\\tbeen\\tleft\\ton\\tthe\\tDursleys'\\tdoorstep\\televen\\tyears\\tbefore.\"],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [None, None, None, None, None, None, None, None, None, None]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_built.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "76XSwG0bxvd1"
   },
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db, n_results=3):\n",
    "  \"\"\"Get relevant passages with better error handling\"\"\"\n",
    "\n",
    "  try:\n",
    "    results=db.query(query_texts=[query], n_results=n_results)\n",
    "    if not results['documents']:\n",
    "      print(\"No results found\")\n",
    "      return None\n",
    "    return results['documents'][0]\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error in query: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_Q-CKJqxyH6",
    "outputId": "b5da5b93-0539-4f91-bf7b-38ccc5e25afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CURRENTLY HEADMASTER OF HOGWARTS\\n\"Are you sure that\\'s a real spell?\" said the girl. \"Well, it\\'s not very good, is it? I\\'ve tried a few simple spells just for practice and it\\'s all worked for me. Nobody in my family\\'s magic at all, it was ever such a surprise when I got my letter, but I was ever so pleased, of course, I mean, it\\'s the very best school of witchcraft there is, I\\'ve heard -I\\'ve learned all our course books by heart, of course, I just hope it will be enough -- I\\'m Hermione Granger, by the way, who are you.\\nShe said all this very fast.\\nHarry looked at Ron, and was relieved to see by his stunned face that he hadn\\'t learned all the course books by heart either.\\n\"I\\'m Ron Weasley,\" Ron muttered.\\n\"Harry Potter,\" said Harry.\\n\"Are you really?\" said Hermione. \"I know all about you, of course -- I got a few extra books. for background reading, and you\\'re in Modern Magical History and The Rise and Fall of the Dark Arts and Great Wizarding Events of the Twentieth Century.\\n\"Am I?\" said Harry, feeling dazed.\\n\"Goodness, didn\\'t you know, I\\'d have found out everything I could if it was me,\" said Hermione. \"Do either of you know what house you\\'ll be in? I\\'ve been asking around, and I hope I\\'m in Gryffindor, it sounds by far the best; I hear Dumbledore himself was in it, but I suppose Ravenclaw wouldn\\'t be too bad.... Anyway, we\\'d better go and look for Neville\\'s toad. You two had better change, you know, I expect we\\'ll be there soon.\"', 'CURRENTLY HEADMASTER OF HOGWARTS\\nAnd she left, taking the toadless boy with her.\\n\"Whatever house I\\'m in, I hope she\\'s not in it,\" said Ron. He threw his wand back into his trunk. \"Stupid spell -- George gave it to me, bet he knew it was a dud.\"\\n\"What house are your brothers in?\" asked Harry.', \"'Miss\\t-\\ter\\t-?'\\n'You\\tall\\tknow,\\tof\\tcourse,\\tthat\\tHogwarts\\twas\\tfounded\\tover\\ta\\tthousand\\tyears ago\\t-\\tthe\\tprecise\\tdate\\tis\\tuncertain\\t-\\tby\\tthe\\tfour\\tgreatest\\twitches\\tand\\twizards of\\tthe\\tage.\\tThe\\tfour\\tschool\\thouses\\tare\\tnamed\\tafter\\tthem:\\tGodric\\tGryffindor, Helga\\tHufflepuff,\\tRowena\\tRavenclaw\\tand\\tSalazar\\tSlytherin.\\tThey\\tbuilt\\tthis castle\\ttogether,\\tfar\\tfrom\\tprying\\tMuggle\\teyes,\\tfor\\tit\\twas\\tan\\tage\\twhen\\tmagic was\\t feared\\t by\\t common\\t people,\\t and\\t witches\\t and\\t wizards\\t suffered\\t much persecution.'\"]\n"
     ]
    }
   ],
   "source": [
    "# Perform embedding search\n",
    "passage = get_relevant_passage(\"where does harry potter go to school?\", collection_built)\n",
    "print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBedAp4zFYk2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "prp_class",
   "language": "python",
   "name": "prp_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}